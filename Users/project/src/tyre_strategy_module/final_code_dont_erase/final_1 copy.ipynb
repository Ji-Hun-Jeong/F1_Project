{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from deap import base, creator, tools, algorithms\n",
    "import io\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import optuna\n",
    "from sklearn.metrics import r2_score, precision_score, f1_score, roc_curve\n",
    "import scipy.stats as sps # stats 대신 sps 라는 별명으로 불러옵니다.\n",
    "import sys\n",
    "sys.path.append(\"/home/azureuser/cloudfiles/code\")\n",
    "\n",
    "from Users.project.src.data_container.data_container import AzureStorageAccess\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#                      <<< F1 전략 최적화 엔진 (완전 통합 버전) >>>\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# [ STEP 1: 설정 ]\n",
    "# ------------------------------------------------------------------------------\n",
    "# track_name = 'Australian' # <--- 분석하고 싶은 트랙 이름만 여기서 변경하세요.\n",
    "# initial_compound = \"D\" # 시뮬레이션 시작 타이어 (필요시 변경)\n",
    "# ------------------------------------------------------------------------------\n",
    "# [ STEP 2: 모든 함수 정의 ]\n",
    "# ------------------------------------------------------------------------------\n",
    "# (이곳에 우리가 만든 모든 함수, 즉 convert_numpy_types, evaluate_strategy,\n",
    "#  create_random_strategy, evaluate_hybrid_strategy, custom_mutate, custom_mate 등을 모두 정의합니다.)\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"\n",
    "    딕셔너리, 리스트를 순회하며 NumPy 타입을 Python 기본 타입으로 변환하는 함수\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    return obj\n",
    "\n",
    "def calculate_pit_proba_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    ROC 곡선을 사용해 pit_proba의 최적 임계값 계산\n",
    "    - 유덴 지수를 최대화하거나 F1 점수를 최적화\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    youden_index = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_index)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # F1 점수 검증 (옵션)\n",
    "    y_pred_binary = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    optimal_f1 = f1_score(y_true, y_pred_binary)\n",
    "    \n",
    "    print(f\"Optimal pit_proba threshold (Youden's Index): {optimal_threshold:.3f}\")\n",
    "    print(f\"Corresponding F1 Score: {optimal_f1:.3f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "def calculate_tyre_wear_threshold(laps_data, percentile=75):\n",
    "    \"\"\"\n",
    "    TyreLife 분포를 분석해 tyre_wear 임계값 계산\n",
    "    - 백분위수 기반, LapTime과의 상관관계 보완\n",
    "    \"\"\"\n",
    "    # TyreLife가 존재하는 데이터 필터링\n",
    "    tyre_data = laps_data.dropna(subset=['TyreLife'])\n",
    "    \n",
    "    # 백분위수 계산\n",
    "    wear_threshold = np.percentile(tyre_data['TyreLife'], percentile)\n",
    "    print(f\"TyreLife {percentile}th percentile threshold: {wear_threshold:.1f}\")\n",
    "    \n",
    "    # LapTime과의 상관관계 분석 (선택적 보완)\n",
    "    corr = tyre_data['TyreLife'].corr(tyre_data['LapTime'])\n",
    "    if abs(corr) > 0.5:\n",
    "        # 상관계수가 높으면, LapTime이 증가하는 지점에서의 TyreLife 임계값 조정\n",
    "        sorted_data = tyre_data.sort_values('TyreLife')\n",
    "        lap_time_increase_idx = np.where(np.diff(sorted_data['LapTime']) > sorted_data['LapTime'].mean() * 0.1)[0]\n",
    "        if len(lap_time_increase_idx) > 0:\n",
    "            adjusted_threshold = sorted_data['TyreLife'].iloc[lap_time_increase_idx[0]] \n",
    "            print(f\"Adjusted threshold based on LapTime increase: {adjusted_threshold:.1f}\")\n",
    "            return adjusted_threshold\n",
    "    return wear_threshold\n",
    "\n",
    "\n",
    "def extract_pit_stop_data(laps_data, track_name, total_laps):\n",
    "    \"\"\"\n",
    "    피트스톱 데이터를 추출하고 다음 컴파운드 선택을 레이블링하는 헬퍼 함수\n",
    "    \"\"\"\n",
    "    pit_stop_list = []\n",
    "    # track_name에 해당하는 데이터만 필터링\n",
    "    track_data = laps_data[laps_data['GrandPrix'].str.contains(track_name, na=False)]\n",
    "    \n",
    "    for (gp, driver), group in track_data.groupby(['GrandPrix', 'Driver']):\n",
    "        group = group.sort_values('LapNumber')\n",
    "        \n",
    "        # PitInTime 또는 IsPitStop 기반 피트스톱 식별\n",
    "        if 'PitInTime' in group.columns and group['PitInTime'].notna().any():\n",
    "            pit_stops = group[group['PitInTime'].notna()].copy()\n",
    "        elif 'IsPitStop' in group.columns and group['IsPitStop'].notna().any():\n",
    "            pit_stops = group[group['IsPitStop'] == 1].copy()\n",
    "        else:\n",
    "            # 위 두 조건에 해당하지 않을 경우, TyreWear 기반으로 추정 (Fallback)\n",
    "            pit_stops = group[group['TyreWear'] >= 28].drop_duplicates(subset=['LapNumber'], keep='first').copy()\n",
    "        \n",
    "        # 다음 랩의 컴파운드를 현재 랩에 할당하여 '선택된 컴파운드'로 사용\n",
    "        pit_stops.loc[:, 'NextCompound'] = pit_stops['Compound'].shift(-1)\n",
    "        \n",
    "        for idx, row in pit_stops[pit_stops['NextCompound'].notnull()].iterrows():\n",
    "            pit_stop_list.append({\n",
    "                'TrackTemp': row['TrackTemp'],\n",
    "                'RemainingLaps': min(total_laps - row['LapNumber'], total_laps),\n",
    "                'ChosenCompound': row['NextCompound']\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(pit_stop_list)\n",
    "\n",
    "def find_compound_choice_thresholds(laps_data, track_name):\n",
    "    \"\"\"\n",
    "    주어진 랩 데이터와 트랙 이름에 대해,\n",
    "    다음 타이어 컴파운드 선택을 가장 잘 예측하는 최적의 임계값 (t1, t2, t3)을 찾습니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    laps_data : pd.DataFrame\n",
    "        분석할 랩 데이터 (Dry 또는 Wet으로 필터링된 데이터)\n",
    "    track_name : str\n",
    "        분석 대상 트랙의 이름 (예: 'Abu_Dhabi')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        최적의 임계값과 해당 임계값에서의 정확도를 담은 딕셔너리\n",
    "        예: {'t1': 30.0, 't2': 15, 't3': 5, 'accuracy': 0.85}\n",
    "    \"\"\"\n",
    "    print(f\"--- {track_name} 트랙의 컴파운드 선택 임계값 계산 시작 ---\")\n",
    "    \n",
    "    # 트랙별 총 랩 수 정의\n",
    "    total_laps_dict = {'Abu_Dhabi': 58, 'Monza': 53, 'Silverstone': 52}\n",
    "    total_laps = total_laps_dict.get(track_name, 58) # 기본값 58랩\n",
    "    \n",
    "    # 피트스톱 데이터 추출\n",
    "    pit_stop_df = extract_pit_stop_data(laps_data, track_name, total_laps)\n",
    "    \n",
    "    if pit_stop_df.empty:\n",
    "        print(f\"경고: {track_name}에서 유효한 피트스톱 데이터를 추출할 수 없습니다. 기본값을 반환합니다.\")\n",
    "        return {\"t1\": 30.0, \"t2\": 29, \"t3\": 11, \"accuracy\": 0.0}\n",
    "\n",
    "    # 그리드 서치로 최적 임계값 찾기\n",
    "    t1_values = np.arange(15.0, 40.0, 1.0)  # TrackTemp\n",
    "    t2_values = np.arange(0.3, 0.9, 0.1)   # RemainingLaps 비율 (긴 주행)\n",
    "    t3_values = np.arange(0.05, 0.25, 0.05) # RemainingLaps 비율 (짧은 주행)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_thresholds = (t1_values[0], int(t2_values[0] * total_laps), int(t3_values[0] * total_laps))\n",
    "\n",
    "    for t1 in t1_values:\n",
    "        for t2_ratio in t2_values:\n",
    "            for t3_ratio in t3_values:\n",
    "                if t3_ratio < t2_ratio:\n",
    "                    t2_laps = int(t2_ratio * total_laps)\n",
    "                    t3_laps = int(t3_ratio * total_laps)\n",
    "                    \n",
    "                    correct = 0\n",
    "                    total = len(pit_stop_df)\n",
    "                    \n",
    "                    if total == 0: continue\n",
    "\n",
    "                    # 예측 로직\n",
    "                    def predict_compound(row):\n",
    "                        if row['TrackTemp'] > t1 or row['RemainingLaps'] > t2_laps:\n",
    "                            return \"HARD\"\n",
    "                        elif row['RemainingLaps'] > t3_laps:\n",
    "                            return \"MEDIUM\"\n",
    "                        else:\n",
    "                            return \"SOFT\"\n",
    "                    \n",
    "                    pit_stop_df['PredictedCompound'] = pit_stop_df.apply(predict_compound, axis=1)\n",
    "                    correct = (pit_stop_df['PredictedCompound'] == pit_stop_df['ChosenCompound']).sum()\n",
    "                    accuracy = correct / total\n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_thresholds = (t1, t2_laps, t3_laps)\n",
    "\n",
    "    # 최종 결과를 딕셔너리 형태로 구성\n",
    "    result = {\n",
    "        \"t1\": best_thresholds[0],\n",
    "        \"t2\": best_thresholds[1],\n",
    "        \"t3\": best_thresholds[2],\n",
    "        \"accuracy\": round(best_accuracy, 2)\n",
    "    }\n",
    "    \n",
    "    print(f\"최적 임계값: t1={result['t1']}°C, t2={result['t2']}랩, t3={result['t3']}랩 (정확도: {result['accuracy']})\")\n",
    "    print(\"--- 계산 완료 ---\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_pit_stop_time(laps_data, track_name):\n",
    "    \"\"\"\n",
    "    피트스톱 시간을 계산하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    laps_data: DataFrame - 랩 데이터 (전처리된 데이터)\n",
    "    track_name: str - 트랙 이름 (예: 'Abu_Dhabi')\n",
    "    \n",
    "    Returns:\n",
    "    float - 평균 피트스톱 시간 (초)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 데이터 유효성 검사\n",
    "    if laps_data is None or laps_data.empty:\n",
    "        print(f\"경고: 데이터가 비어있습니다. 기본값(22초) 사용.\")\n",
    "        return 22.0\n",
    "    \n",
    "    # 필요한 컬럼들이 존재하는지 확인\n",
    "    required_columns = ['GrandPrix', 'PitInTime', 'PitOutTime', 'LapNumber', 'Driver']\n",
    "    missing_columns = [col for col in required_columns if col not in laps_data.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"경고: 필요한 컬럼들이 누락되었습니다: {missing_columns}\")\n",
    "        print(f\"사용 가능한 컬럼들: {list(laps_data.columns)}\")\n",
    "        return 22.0\n",
    "    \n",
    "    # 해당 트랙 데이터 필터링\n",
    "    try:\n",
    "        track_data = laps_data[laps_data['GrandPrix'].str.contains(track_name, na=False)].copy()\n",
    "        if track_data.empty:\n",
    "            print(f\"경고: {track_name} 트랙 데이터를 찾을 수 없습니다.\")\n",
    "            print(f\"사용 가능한 트랙들: {laps_data['GrandPrix'].unique()}\")\n",
    "            return 22.0\n",
    "            \n",
    "        print(f\"{track_name} 데이터 발견: {len(track_data)} 행\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"경고: 데이터 필터링 중 오류 발생: {e}. 기본값(22초) 사용.\")\n",
    "        return 22.0\n",
    "\n",
    "    pit_times = []\n",
    "    \n",
    "    # 각 드라이버별로 피트스톱 시간 계산\n",
    "    for driver in track_data['Driver'].unique():\n",
    "        driver_data = track_data[track_data['Driver'] == driver].sort_values('LapNumber').reset_index(drop=True)\n",
    "        \n",
    "        # PitInTime이 있는 랩들 찾기\n",
    "        pit_in_laps = driver_data[driver_data['PitInTime'].notna()]\n",
    "        \n",
    "        for _, pit_in_row in pit_in_laps.iterrows():\n",
    "            try:\n",
    "                pit_in_lap = pit_in_row['LapNumber']\n",
    "                pit_in_time_str = str(pit_in_row['PitInTime'])\n",
    "                \n",
    "                # 해당 드라이버의 다음 랩들에서 PitOutTime 찾기\n",
    "                next_laps = driver_data[driver_data['LapNumber'] > pit_in_lap]\n",
    "                pit_out_row = next_laps[next_laps['PitOutTime'].notna()].head(1)\n",
    "                \n",
    "                if pit_out_row.empty:\n",
    "                    print(f\"경고: {driver} 드라이버의 랩 {pit_in_lap}에서 PitOutTime을 찾을 수 없습니다. 건너뜁니다.\")\n",
    "                    continue\n",
    "                \n",
    "                pit_out_time_str = str(pit_out_row['PitOutTime'].iloc[0])\n",
    "                \n",
    "                # 시간 파싱\n",
    "                try:\n",
    "                    # timedelta 형식 처리\n",
    "                    if 'days' in pit_in_time_str:\n",
    "                        pit_in_time = pd.to_timedelta(pit_in_time_str)\n",
    "                    else:\n",
    "                        pit_in_time = pd.to_timedelta(f'0 days {pit_in_time_str}')\n",
    "                        \n",
    "                    if 'days' in pit_out_time_str:\n",
    "                        pit_out_time = pd.to_timedelta(pit_out_time_str)\n",
    "                    else:\n",
    "                        pit_out_time = pd.to_timedelta(f'0 days {pit_out_time_str}')\n",
    "                    \n",
    "                except Exception as parse_error:\n",
    "                    print(f\"경고: {driver} 드라이버의 시간 파싱 오류: {parse_error}. 건너뜁니다.\")\n",
    "                    continue\n",
    "                \n",
    "                # 피트스톱 시간 계산\n",
    "                pit_stop_time = (pit_out_time - pit_in_time).total_seconds()\n",
    "                \n",
    "                # 유효성 검사 (10초 ~ 120초)\n",
    "                if pit_stop_time <= 0:\n",
    "                    print(f\"경고: {driver} 드라이버의 랩 {pit_in_lap}에서 음수 또는 0인 피트스톱 시간: {pit_stop_time:.2f}초. 건너뜁니다.\")\n",
    "                    continue\n",
    "                    \n",
    "                if 10 < pit_stop_time < 120:\n",
    "                    pit_times.append(pit_stop_time)\n",
    "                    print(f\"{driver} 드라이버 랩 {pit_in_lap}: 피트스톱 시간 {pit_stop_time:.2f}초\")\n",
    "                else:\n",
    "                    print(f\"경고: {driver} 드라이버의 랩 {pit_in_lap}에서 비정상적인 피트스톱 시간: {pit_stop_time:.2f}초. 건너뜁니다.\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"경고: {driver} 드라이버의 데이터 처리 중 오류: {e}. 건너뜁니다.\")\n",
    "                continue\n",
    "\n",
    "    # 결과 처리\n",
    "    if not pit_times:\n",
    "        print(f\"경고: {track_name}에 유효한 피트스톱 시간이 없습니다. 기본값(22초) 사용.\")\n",
    "        return 22.0\n",
    "\n",
    "    # 평균 피트스톱 시간 계산\n",
    "    avg_pit_stop_time = np.mean(pit_times)\n",
    "    print(f\"\\n{track_name} 평균 피트스톱 시간: {avg_pit_stop_time:.2f}초 (유효 데이터 수: {len(pit_times)})\")\n",
    "    return avg_pit_stop_time\n",
    "\n",
    "def analyze_pit_stops_by_track(laps_data):\n",
    "    \"\"\"\n",
    "    모든 트랙별 피트스톱 시간 분석\n",
    "    \"\"\"\n",
    "    print(\"=== 트랙별 피트스톱 시간 분석 ===\")\n",
    "    \n",
    "    if 'GrandPrix' not in laps_data.columns:\n",
    "        print(\"GrandPrix 컬럼이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    tracks = laps_data['GrandPrix'].unique()\n",
    "    results = {}\n",
    "    \n",
    "    for track in tracks:\n",
    "        track_name = track.split('_')[-3] if '_' in track else track  # 'Abu_Dhabi' 추출\n",
    "        print(f\"\\n--- {track} 분석 ---\")\n",
    "        pit_cost = calculate_pit_stop_time(laps_data, track_name)\n",
    "        results[track] = pit_cost\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_degradation_rate_v2(laps_data):\n",
    "    # (이전과 동일한 함수 내용)\n",
    "    base_rates = {\n",
    "        'SOFT': 0.035, 'MEDIUM': 0.022, 'HARD': 0.013,\n",
    "        'INTERMEDIATE': 0.045, 'WET': 0.080\n",
    "    }\n",
    "    # ... (함수 내용 전체) ...\n",
    "    tyre_data = laps_data.dropna(subset=['LapTime', 'TyreLife', 'Compound'])\n",
    "    degradation_rates = {}\n",
    "    \n",
    "    for compound in tyre_data['Compound'].unique():\n",
    "        if compound not in base_rates:\n",
    "            continue\n",
    "        compound_data = tyre_data[tyre_data['Compound'] == compound]\n",
    "        if len(compound_data) > 20:\n",
    "            intervals = []\n",
    "            for start_life in range(1, 31, 5):\n",
    "                interval_data = compound_data[\n",
    "                    (compound_data['TyreLife'] >= start_life) & \n",
    "                    (compound_data['TyreLife'] < start_life + 5)\n",
    "                ]\n",
    "                if len(interval_data) > 0:\n",
    "                    intervals.append({\n",
    "                        'start_life': start_life,\n",
    "                        'avg_time': interval_data['LapTime'].median()\n",
    "                    })\n",
    "            if len(intervals) >= 3:\n",
    "                time_increases = []\n",
    "                for i in range(1, len(intervals)):\n",
    "                    prev_time = intervals[i-1]['avg_time']\n",
    "                    curr_time = intervals[i]['avg_time']\n",
    "                    increase_rate = (curr_time - prev_time) / prev_time\n",
    "                    time_increases.append(increase_rate)\n",
    "                if time_increases:\n",
    "                    degradation_rate = np.mean(time_increases) * 5\n",
    "                    degradation_rates[compound] = max(0.005, min(0.08, abs(degradation_rate)))\n",
    "                else:\n",
    "                    degradation_rates[compound] = base_rates[compound]\n",
    "            else:\n",
    "                degradation_rates[compound] = base_rates[compound]\n",
    "        else:\n",
    "            degradation_rates[compound] = base_rates[compound]\n",
    "\n",
    "    for compound in base_rates:\n",
    "        if compound not in degradation_rates:\n",
    "            degradation_rates[compound] = base_rates[compound]\n",
    "    \n",
    "    # 드라이 타이어에 대해서만 순서 보장\n",
    "    dry_compounds = ['HARD', 'MEDIUM', 'SOFT']\n",
    "    dry_rates = [degradation_rates.get(c) for c in dry_compounds if c in degradation_rates]\n",
    "    \n",
    "    if len(dry_rates) == 3: # 드라이 컴파운드가 모두 있을 때만 정렬\n",
    "        dry_rates.sort()\n",
    "        for i, compound in enumerate(dry_compounds):\n",
    "            degradation_rates[compound] = dry_rates[i]\n",
    "    \n",
    "    return degradation_rates\n",
    "\n",
    "\n",
    "def calculate_stint_params_proper(laps_data):\n",
    "    # (이전과 동일한 함수 내용 및 의존 함수들 포함)\n",
    "    # ... (filter_performance_based_stints, analyze_stint_distribution, validate_stint_logic 등)\n",
    "    pit_data = laps_data.dropna(subset=['PitInTime', 'LapNumber', 'Driver', 'Compound'])\n",
    "    pit_data = pit_data.sort_values(['Driver', 'Time'])\n",
    "    pit_data['NextPitLap'] = pit_data.groupby('Driver')['LapNumber'].shift(-1)\n",
    "    pit_data['StintLength'] = pit_data['NextPitLap'] - pit_data['LapNumber']\n",
    "    stint_data = pit_data[pit_data['StintLength'] > 0].dropna(subset=['StintLength', 'Compound'])\n",
    "    \n",
    "    optimal_stint = {}\n",
    "    min_stint = {}\n",
    "    \n",
    "    performance_based_stints = filter_performance_based_stints(stint_data, laps_data)\n",
    "    \n",
    "    theoretical_values = {\n",
    "        'SOFT': 16, 'MEDIUM': 25, 'HARD': 35,\n",
    "        'INTERMEDIATE': 20, 'WET': 12\n",
    "    }\n",
    "    \n",
    "    # 모든 컴파운드에 대해 계산\n",
    "    all_compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "    for compound in all_compounds:\n",
    "        if compound not in laps_data['Compound'].unique():\n",
    "            continue\n",
    "            \n",
    "        compound_stints = performance_based_stints.get(compound, [])\n",
    "        \n",
    "        if len(compound_stints) >= 5:\n",
    "            stint_analysis = analyze_stint_distribution(compound_stints)\n",
    "            optimal_stint[compound] = stint_analysis['recommended']\n",
    "        else:\n",
    "            optimal_stint[compound] = theoretical_values[compound]\n",
    "        \n",
    "        min_stint[compound] = 8 if compound in ['SOFT', 'MEDIUM', 'HARD'] else 5\n",
    "        print(f\"{compound}: {len(compound_stints)} quality stints, optimal={optimal_stint.get(compound)} laps\")\n",
    "    \n",
    "    validated_stints = validate_stint_logic(optimal_stint, theoretical_values)\n",
    "    \n",
    "    return validated_stints, min_stint\n",
    "\n",
    "\n",
    "def filter_performance_based_stints(stint_data, laps_data):\n",
    "    \"\"\"\n",
    "    성능 기반으로 유효한 stint만 필터링\n",
    "    - 전략적/비정상적 stint 제외\n",
    "    - 타이어별 특성을 고려한 필터링\n",
    "    \"\"\"\n",
    "    filtered_stints = {}\n",
    "    \n",
    "    for compound in stint_data['Compound'].unique():\n",
    "        compound_stints = stint_data[stint_data['Compound'] == compound].copy()\n",
    "        \n",
    "        # 1. 기본 범위 필터링\n",
    "        if compound == 'SOFT':\n",
    "            valid_range = (8, 25)  # 소프트는 짧은 범위\n",
    "        elif compound == 'MEDIUM':\n",
    "            valid_range = (12, 35) # 미디엄은 중간 범위\n",
    "        else:  # HARD\n",
    "            valid_range = (18, 45) # 하드는 긴 범위\n",
    "        \n",
    "        in_range_stints = compound_stints[\n",
    "            (compound_stints['StintLength'] >= valid_range[0]) &\n",
    "            (compound_stints['StintLength'] <= valid_range[1])\n",
    "        ]\n",
    "        \n",
    "        # 2. 성능 기반 필터링 (레이스 페이스가 정상적인 stint만)\n",
    "        performance_filtered = filter_by_race_performance(in_range_stints, laps_data, compound)\n",
    "        \n",
    "        # 3. 통계적 이상치 제거\n",
    "        if len(performance_filtered) > 10:\n",
    "            Q1 = performance_filtered['StintLength'].quantile(0.25)\n",
    "            Q3 = performance_filtered['StintLength'].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            final_stints = performance_filtered[\n",
    "                (performance_filtered['StintLength'] >= Q1 - 1.5 * IQR) &\n",
    "                (performance_filtered['StintLength'] <= Q3 + 1.5 * IQR)\n",
    "            ]\n",
    "        else:\n",
    "            final_stints = performance_filtered\n",
    "        \n",
    "        # final_stints가 비어있지 않을 때만 컬럼에 접근\n",
    "        if not final_stints.empty:\n",
    "            filtered_stints[compound] = final_stints['StintLength'].tolist()\n",
    "        else:\n",
    "            filtered_stints[compound] = []\n",
    "        \n",
    "        print(f\"{compound}: {len(compound_stints)} → {len(final_stints)} stints after filtering\")\n",
    "    \n",
    "    return filtered_stints\n",
    "\n",
    "\n",
    "\n",
    "def filter_by_race_performance(stint_data, laps_data, compound):\n",
    "    \"\"\"\n",
    "    레이스 성능을 고려한 stint 필터링\n",
    "    - 비정상적으로 느린 페이스의 stint 제외\n",
    "    - Safety Car, 트래픽 등으로 인한 왜곡 제거\n",
    "    \"\"\"\n",
    "    if stint_data.empty:\n",
    "        return stint_data\n",
    "    \n",
    "    # 해당 컴파운드의 정상 성능 범위 계산\n",
    "    compound_laps = laps_data[laps_data['Compound'] == compound]\n",
    "    if len(compound_laps) < 50:\n",
    "        return stint_data  # 데이터 부족시 필터링 건너뛰기\n",
    "    \n",
    "    # 정상 랩타임 범위 (25-75% 백분위수)\n",
    "    normal_lap_range = (\n",
    "        compound_laps['LapTime'].quantile(0.25),\n",
    "        compound_laps['LapTime'].quantile(0.75)\n",
    "    )\n",
    "    \n",
    "    valid_stints = []\n",
    "    \n",
    "    for _, stint_row in stint_data.iterrows():\n",
    "        driver = stint_row['Driver']\n",
    "        start_lap = stint_row['LapNumber']\n",
    "        end_lap = start_lap + stint_row['StintLength']\n",
    "        \n",
    "        # 해당 stint의 랩타임들 조회\n",
    "        stint_laps = laps_data[\n",
    "            (laps_data['Driver'] == driver) &\n",
    "            (laps_data['LapNumber'] >= start_lap) &\n",
    "            (laps_data['LapNumber'] < end_lap) &\n",
    "            (laps_data['Compound'] == compound)\n",
    "        ]\n",
    "        \n",
    "        if len(stint_laps) >= stint_row['StintLength'] * 0.7:  # 70% 이상 데이터 있음\n",
    "            # stint 평균 페이스가 정상 범위에 있는지 확인\n",
    "            stint_avg_time = stint_laps['LapTime'].median()\n",
    "            \n",
    "            if normal_lap_range[0] <= stint_avg_time <= normal_lap_range[1] * 1.1:  # 약간의 여유\n",
    "                valid_stints.append(stint_row)\n",
    "    \n",
    "    return pd.DataFrame(valid_stints) if valid_stints else pd.DataFrame()\n",
    "\n",
    "\n",
    "def analyze_stint_distribution(stint_lengths):\n",
    "    \"\"\"\n",
    "    stint 길이 분포 분석으로 최적값 도출\n",
    "    \"\"\"\n",
    "    stint_array = np.array(stint_lengths)\n",
    "    \n",
    "    analysis = {\n",
    "        'mean': np.mean(stint_array),\n",
    "        'median': np.median(stint_array),\n",
    "        'mode': float(sps.mode(stint_array, keepdims=False)[0]) if len(stint_array) > 0 else np.median(stint_array),\n",
    "        'p75': np.percentile(stint_array, 75),  # 상위 25% 평균\n",
    "        'recommended': 0\n",
    "    }\n",
    "    \n",
    "    # 다양한 통계값의 가중평균으로 추천값 계산\n",
    "    # 중간값(40%) + 75%ile(30%) + 평균(20%) + 최빈값(10%)\n",
    "    analysis['recommended'] = int(\n",
    "        analysis['median'] * 0.4 +\n",
    "        analysis['p75'] * 0.3 +\n",
    "        analysis['mean'] * 0.2 +\n",
    "        analysis['mode'] * 0.1\n",
    "    )\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "\n",
    "def validate_stint_logic(optimal_stint, theoretical_values):\n",
    "    \"\"\"\n",
    "    논리적 검증 및 미세 조정 (강제 변경 대신 경고 및 보정)\n",
    "    \"\"\"\n",
    "    validated = optimal_stint.copy()\n",
    "    adjustments_made = False\n",
    "    \n",
    "    # 검증 1: 기본 순서 확인\n",
    "    if validated.get('SOFT', 0) >= validated.get('MEDIUM', 0):\n",
    "        print(f\"⚠️  WARNING: SOFT stint ({validated.get('SOFT')}) >= MEDIUM stint ({validated.get('MEDIUM')})\")\n",
    "        \n",
    "        # 데이터 신뢰도 기반 조정\n",
    "        if 'SOFT' in validated and 'MEDIUM' in validated:\n",
    "            # 이론값과의 편차가 큰 쪽을 이론값에 가깝게 조정\n",
    "            soft_deviation = abs(validated['SOFT'] - theoretical_values['SOFT'])\n",
    "            medium_deviation = abs(validated['MEDIUM'] - theoretical_values['MEDIUM'])\n",
    "            \n",
    "            if soft_deviation > medium_deviation:\n",
    "                validated['SOFT'] = int((validated['SOFT'] + theoretical_values['SOFT']) / 2)\n",
    "                adjustments_made = True\n",
    "                print(f\"   → SOFT adjusted to {validated['SOFT']}\")\n",
    "    \n",
    "    # 검증 2: MEDIUM vs HARD\n",
    "    if validated.get('MEDIUM', 0) >= validated.get('HARD', 0):\n",
    "        print(f\"⚠️  WARNING: MEDIUM stint ({validated.get('MEDIUM')}) >= HARD stint ({validated.get('HARD')})\")\n",
    "        \n",
    "        if 'MEDIUM' in validated and 'HARD' in validated:\n",
    "            medium_deviation = abs(validated['MEDIUM'] - theoretical_values['MEDIUM'])\n",
    "            hard_deviation = abs(validated['HARD'] - theoretical_values['HARD'])\n",
    "            \n",
    "            if medium_deviation > hard_deviation:\n",
    "                validated['MEDIUM'] = int((validated['MEDIUM'] + theoretical_values['MEDIUM']) / 2)\n",
    "                adjustments_made = True\n",
    "                print(f\"   → MEDIUM adjusted to {validated['MEDIUM']}\")\n",
    "            else:\n",
    "                validated['HARD'] = int((validated['HARD'] + theoretical_values['HARD']) / 2)\n",
    "                adjustments_made = True\n",
    "                print(f\"   → HARD adjusted to {validated['HARD']}\")\n",
    "    \n",
    "    if adjustments_made:\n",
    "        print(\"✅ Logical adjustments completed based on data quality\")\n",
    "    else:\n",
    "        print(\"✅ All stint values follow logical order\")\n",
    "    \n",
    "    return validated\n",
    "\n",
    "\n",
    "def calculate_temp_threshold(laps_data):\n",
    "    \"\"\"\n",
    "    TrackTemp와 LapTime 간 상관관계를 분석해 temp_threshold 계산\n",
    "    - 최소 포인트 수 20 필터링\n",
    "    \"\"\"\n",
    "    temp_data = laps_data.dropna(subset=['LapTime', 'TrackTemp', 'Compound'])\n",
    "    temp_bins = np.linspace(temp_data['TrackTemp'].min(), temp_data['TrackTemp'].max(), 10)\n",
    "    \n",
    "    temp_threshold = {}\n",
    "    for compound in temp_data['Compound'].unique():\n",
    "        compound_data = temp_data[temp_data['Compound'] == compound].copy()\n",
    "        compound_data.loc[:, 'TempBin'] = pd.cut(compound_data['TrackTemp'], bins=temp_bins, labels=[i for i in range(len(temp_bins)-1)])\n",
    "        \n",
    "        temp_means = compound_data.groupby('TempBin', observed=True).agg({'LapTime': 'mean'})\n",
    "        if temp_means.empty:\n",
    "            temp_threshold[compound] = compound_data['TrackTemp'].mean()\n",
    "        else:\n",
    "            valid_bins = compound_data['TempBin'].value_counts()[compound_data['TempBin'].value_counts() >= 20].index\n",
    "            temp_means = temp_means.loc[valid_bins]\n",
    "            if not temp_means.empty:\n",
    "                base_mean = temp_means['LapTime'].min()\n",
    "                max_increase_idx = (temp_means['LapTime'] - base_mean > base_mean * 0.1).idxmax()\n",
    "                if max_increase_idx in valid_bins:\n",
    "                    temp_threshold[compound] = (temp_bins[max_increase_idx] + temp_bins[max_increase_idx + 1]) / 2\n",
    "                else:\n",
    "                    temp_threshold[compound] = compound_data['TrackTemp'].mean()\n",
    "            else:\n",
    "                temp_threshold[compound] = compound_data['TrackTemp'].mean()\n",
    "        print(f\"{compound}: Calculated temp_threshold = {temp_threshold[compound]:.1f}°C, Temp means = {temp_means['LapTime'].to_dict()}, Points per bin = {compound_data['TempBin'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return temp_threshold\n",
    "\n",
    "\n",
    "def calculate_base_pace(laps_data):\n",
    "    \"\"\"\n",
    "    초기 스틴트의 평균 LapTime을 이용해 base_pace 계산\n",
    "    - 모든 컴파운드(WET, INTERMEDIATE 포함)를 처리하도록 수정됨\n",
    "    \"\"\"\n",
    "    pace_data = laps_data.dropna(subset=['LapTime', 'Compound', 'TyreLife'])\n",
    "    # TyreLife가 1 이하인 랩만 필터링하여 각 타이어의 초기 성능을 확인\n",
    "    pace_data = pace_data[pace_data['TyreLife'] <= 1]\n",
    "    \n",
    "    base_paces = {}\n",
    "    \n",
    "    # 데이터에 존재하는 모든 고유 컴파운드에 대해 반복\n",
    "    for compound in pace_data['Compound'].unique():\n",
    "        compound_mean = pace_data[pace_data['Compound'] == compound]['LapTime'].mean()\n",
    "        \n",
    "        # 유효한 랩타임이 있는 경우에만 pace를 계산\n",
    "        if pd.notna(compound_mean) and compound_mean > 0:\n",
    "            if compound == 'SOFT':\n",
    "                base_paces[compound] = 1.0  # 기준 속도\n",
    "            elif compound == 'MEDIUM':\n",
    "                base_paces[compound] = 0.98 # SOFT보다 약간 느림\n",
    "            elif compound == 'HARD':\n",
    "                base_paces[compound] = 0.96 # MEDIUM보다 약간 느림\n",
    "            elif compound == 'INTERMEDIATE':\n",
    "                base_paces[compound] = 0.85 # 드라이 타이어보다 확연히 느림\n",
    "            elif compound == 'WET':\n",
    "                base_paces[compound] = 0.75 # 가장 느림\n",
    "            else:\n",
    "                # 'Unknown' 등 예상치 못한 컴파운드에 대한 안전장치\n",
    "                base_paces[compound] = 0.70 \n",
    "        \n",
    "        # base_paces 딕셔너리에 해당 compound가 있는지 확인 후 출력 (KeyError 방지)\n",
    "        if compound in base_paces:\n",
    "            print(f\"{compound} initial data points: {len(pace_data[pace_data['Compound'] == compound])}, base_pace = {base_paces[compound]}\")\n",
    "        else:\n",
    "            # pace가 계산되지 않은 경우 (e.g., 유효한 랩타임이 없는 경우)\n",
    "            print(f\"{compound} initial data points: {len(pace_data[pace_data['Compound'] == compound])}, base_pace calculation skipped.\")\n",
    "\n",
    "    print(\"\\nCalculated base_pace:\", base_paces)\n",
    "    return base_paces\n",
    "\n",
    "\n",
    "def calculate_all_compound_performance(laps_data):\n",
    "    \"\"\"\n",
    "    주어진 랩 데이터에 대해 모든 통계 기반 컴파운드 성능 파라미터를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    laps_data : pd.DataFrame\n",
    "        분석할 랩 데이터 (Dry 또는 Wet으로 필터링된 데이터)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        각 컴파운드별 성능 파라미터(base_pace, degradation_rate 등)를 포함하는 \n",
    "        중첩된 딕셔너리.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== 컴파운드 성능 파라미터 계산 시작 ===\")\n",
    "    \n",
    "    # 1. 각 파라미터 계산\n",
    "    base_paces = calculate_base_pace(laps_data)\n",
    "    degradation_rates = calculate_degradation_rate_v2(laps_data)\n",
    "    optimal_stint, min_stint = calculate_stint_params_proper(laps_data)\n",
    "    temp_threshold = calculate_temp_threshold(laps_data)\n",
    "\n",
    "    # 2. 결과 통합\n",
    "    compound_performance = {}\n",
    "    \n",
    "    # laps_data에 존재하는 고유한 컴파운드 목록에 대해서만 반복\n",
    "    existing_compounds = laps_data['Compound'].unique()\n",
    "    \n",
    "    for compound in existing_compounds:\n",
    "        # 계산된 값이 없는 경우를 대비하여 기본값(get 메서드의 두 번째 인자) 설정\n",
    "        compound_performance[compound] = {\n",
    "            \"base_pace\": base_paces.get(compound, 0.95),\n",
    "            \"degradation_rate\": degradation_rates.get(compound, 0.05),\n",
    "            \"optimal_stint\": optimal_stint.get(compound, 15),\n",
    "            \"min_stint\": min_stint.get(compound, 10),\n",
    "            \"temp_threshold\": temp_threshold.get(compound, 28.3)\n",
    "        }\n",
    "    \n",
    "    print(\"\\n=== 컴파운드 성능 파라미터 계산 완료 ===\")\n",
    "    print(compound_performance)\n",
    "    \n",
    "    return compound_performance\n",
    "\n",
    "def select_next_compound(current_compound, used_compounds, rainfall, track_temp, current_lap, race_laps, pit_count, params):\n",
    "    \"\"\"\n",
    "    다음으로 사용할 타이어 컴파운드를 선택하는 헬퍼 함수\n",
    "    - 현재 날씨와 레이스 상황에 맞는 파라미터(params)를 사용\n",
    "    \"\"\"\n",
    "    remaining_laps = race_laps - current_lap\n",
    "    \n",
    "    # 1. 날씨 기반 선택 (최우선)\n",
    "    if rainfall > 0.1 and 'wet_strategy_params' in params:\n",
    "        # 비가 오면 Wet 파라미터를 사용해야 함\n",
    "        wet_compounds = params['wet_strategy_params']['compound_performance']\n",
    "        if \"WET\" in wet_compounds and rainfall > 2.0: # 강한 비\n",
    "             return \"WET\"\n",
    "        if \"INTERMEDIATE\" in wet_compounds:\n",
    "            return \"INTERMEDIATE\"\n",
    "\n",
    "    # 2. Dry 날씨 기반 선택\n",
    "    # 사용 가능한 Dry 타이어\n",
    "    dry_params = params['dry_strategy_params']\n",
    "    available_dry = {\"SOFT\", \"MEDIUM\", \"HARD\"} - used_compounds\n",
    "    \n",
    "    # 파라미터에서 t1, t2, t3 임계값 가져오기\n",
    "    thresholds = dry_params['compound_choice_thresholds']\n",
    "    t1, t2, t3 = thresholds['t1'], thresholds['t2'], thresholds['t3']\n",
    "    \n",
    "    if track_temp > t1 and \"HARD\" in available_dry:\n",
    "        return \"HARD\"\n",
    "    elif remaining_laps > t2 and \"HARD\" in available_dry:\n",
    "        return \"HARD\"\n",
    "    elif remaining_laps > t3 and \"MEDIUM\" in available_dry:\n",
    "        return \"MEDIUM\"\n",
    "    \n",
    "    # Fallback 로직: 가능한 타이어 중 가장 내구성이 좋은 순서대로 선택\n",
    "    if \"SOFT\" in available_dry and pit_count == 0:\n",
    "        return \"SOFT\"\n",
    "    if \"MEDIUM\" in available_dry:\n",
    "        return \"MEDIUM\"\n",
    "    if \"HARD\" in available_dry:\n",
    "        return \"HARD\"\n",
    "        \n",
    "    # 모든 Dry 타이어를 이미 사용했다면, 가장 내구성이 좋은 타이어 중 하나를 다시 선택\n",
    "    return \"MEDIUM\" if \"MEDIUM\" in dry_params['compound_performance'] else \"HARD\"\n",
    "\n",
    "\n",
    "def run_race_simulation(lap_data_df, params_data, initial_tyre=\"HARD\", race_laps=58):\n",
    "    \"\"\"\n",
    "    전체 레이스를 시뮬레이션하고 최적의 피트 스톱 전략을 도출합니다.\n",
    "    - 날씨에 따라 동적으로 파라미터를 선택합니다.\n",
    "    \"\"\"\n",
    "    df_race = lap_data_df[lap_data_df['lap'] <= race_laps].copy()\n",
    "\n",
    "    print(f\"Race simulation started: Laps 1-{race_laps}\")\n",
    "    print(f\"Initial compound: {initial_tyre}\")\n",
    "    \n",
    "    strategy = []\n",
    "    used_compounds = {initial_tyre}\n",
    "    current_compound = initial_tyre\n",
    "    last_pit_lap = 0\n",
    "    current_stint_length = 0\n",
    "    total_time = 0.0\n",
    "    pit_count = 0\n",
    "    \n",
    "    for _, row in lap_data_df.iterrows():\n",
    "        lap_num = int(row['lap'])\n",
    "        current_stint_length += 1\n",
    "        \n",
    "        # --- ⭐️ 동적 파라미터 선택 (핵심 수정) ⭐️ ---\n",
    "        is_wet = row['rainfall'] > 0\n",
    "        if is_wet and 'wet_strategy_params' in params_data:\n",
    "            active_params = params_data['wet_strategy_params']\n",
    "        else:\n",
    "            active_params = params_data['dry_strategy_params']\n",
    "        \n",
    "        # 현재 컴파운드가 active_params에 없으면 Dry 파라미터로 fallback\n",
    "        if current_compound not in active_params['compound_performance']:\n",
    "            active_params = params_data['dry_strategy_params']\n",
    "            \n",
    "        perf = active_params['compound_performance'][current_compound]\n",
    "        pit_cost = active_params['pit_stop_time']\n",
    "        \n",
    "        # 랩타임 계산\n",
    "        degradation = 1 + (perf[\"degradation_rate\"] * current_stint_length / 100)\n",
    "        adjusted_laptime = row['laptime'] * perf[\"base_pace\"] * degradation\n",
    "        total_time += adjusted_laptime\n",
    "        \n",
    "        # 피트스톱 결정 로직\n",
    "        should_pit = False\n",
    "        pit_reason = \"\"\n",
    "        \n",
    "        # Dry/Wet 공통 조건: 최소 스틴트 길이 충족 및 최대 피트 횟수 미만\n",
    "        if lap_num - last_pit_lap >= perf.get(\"min_stint\", 5) and pit_count < 3:\n",
    "            if not is_wet: # Dry 로직\n",
    "                if (row['pit_proba'] > active_params['pit_proba_threshold'] and \\\n",
    "                    current_stint_length >= perf[\"optimal_stint\"] * 0.9) or \\\n",
    "                   (row['tyre_wear'] > active_params['TyreLife_threshold']):\n",
    "                    should_pit = True\n",
    "                    pit_reason = f\"ML-Predict(Prob:{row['pit_proba']:.2f}, Wear:{row['tyre_wear']:.1f})\"\n",
    "            else: # Wet 로직\n",
    "                if current_stint_length >= perf[\"optimal_stint\"]:\n",
    "                    should_pit = True\n",
    "                    pit_reason = f\"Wet-Stint({current_stint_length}/{perf['optimal_stint']})\"\n",
    "\n",
    "            # 날씨 변화로 인한 강제 피트스톱\n",
    "            if is_wet and current_compound in [\"SOFT\", \"MEDIUM\", \"HARD\"]:\n",
    "                should_pit = True\n",
    "                pit_reason = f\"RAIN! Change to Wet-Tyre\"\n",
    "            elif not is_wet and current_compound in [\"INTERMEDIATE\", \"WET\"]:\n",
    "                 should_pit = True\n",
    "                 pit_reason = f\"TRACK DRY! Change to Dry-Tyre\"\n",
    "        \n",
    "        if should_pit:\n",
    "            total_time += pit_cost\n",
    "            next_compound = select_next_compound(current_compound, used_compounds, row['rainfall'], \n",
    "                                                 row['track_temp'], lap_num, race_laps, pit_count, params_data)\n",
    "            \n",
    "            strategy.append({\n",
    "                \"lap\": lap_num, \"from_tyre\": current_compound, \"to_tyre\": next_compound,\n",
    "                \"reason\": pit_reason, \"stint_length\": current_stint_length\n",
    "            })\n",
    "            print(f\"Lap {lap_num}: PIT! {current_compound}->{next_compound} ({pit_reason})\")\n",
    "            \n",
    "            used_compounds.add(next_compound)\n",
    "            current_compound = next_compound\n",
    "            last_pit_lap = lap_num\n",
    "            current_stint_length = 0\n",
    "            pit_count += 1\n",
    "    \n",
    "    print(\"\\nRace simulation complete:\")\n",
    "    print(f\"- Total race time: {total_time/60:.2f} minutes\")\n",
    "    return total_time, strategy\n",
    "\n",
    "# 데이터 전처리 및 정렬 (수정된 부분)\n",
    "def fix_time_sorting(df, time_col='Time', group_col='GrandPrix'):\n",
    "    \"\"\"\n",
    "    시간 컬럼의 정렬 문제를 수정하는 함수\n",
    "    \"\"\"\n",
    "    # NaN 값 제거\n",
    "    df = df.dropna(subset=[time_col]).copy()\n",
    "    \n",
    "    # datetime으로 변환\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    \n",
    "    # 각 그룹별로 정렬 확인 및 수정\n",
    "    fixed_groups = []\n",
    "    \n",
    "    for group_name in df[group_col].unique():\n",
    "        group_data = df[df[group_col] == group_name].copy()\n",
    "        \n",
    "        # 시간순으로 정렬\n",
    "        group_data = group_data.sort_values(time_col).reset_index(drop=True)\n",
    "        \n",
    "        # 정렬 확인\n",
    "        if not group_data[time_col].is_monotonic_increasing:\n",
    "            print(f\"Warning: {group_name} has non-monotonic time values, fixing...\")\n",
    "            # 중복된 시간값이 있을 경우 미세하게 조정\n",
    "            duplicated = group_data[time_col].duplicated()\n",
    "            if duplicated.any():\n",
    "                print(f\"Found {duplicated.sum()} duplicate time values in {group_name}\")\n",
    "                # 중복된 시간에 microsecond 추가\n",
    "                for i, is_dup in enumerate(duplicated):\n",
    "                    if is_dup:\n",
    "                        group_data.iloc[i, group_data.columns.get_loc(time_col)] += pd.Timedelta(microseconds=i)\n",
    "        \n",
    "        fixed_groups.append(group_data)\n",
    "        print(f\"Fixed {group_name}: {len(group_data)} rows, time range: {group_data[time_col].min()} to {group_data[time_col].max()}\")\n",
    "    \n",
    "    return pd.concat(fixed_groups, ignore_index=True)\n",
    "def evaluate_strategy(lap_data_df, params_data, strategy_plan, initial_tyre, race_laps):\n",
    "    # strategy_plan 예시: [{'lap': 15, 'tyre': 'HARD'}, {'lap': 30, 'tyre': 'MEDIUM'}]\n",
    "    \n",
    "    total_time = 0.0\n",
    "    current_compound = initial_tyre\n",
    "    last_pit_lap = 0\n",
    "    \n",
    "    pit_stops = {s['lap']: s['tyre'] for s in strategy_plan}\n",
    "\n",
    "    for _, row in lap_data_df.iterrows():\n",
    "        lap_num = int(row['lap'])\n",
    "        \n",
    "        # 피트 스톱 수행\n",
    "        if lap_num in pit_stops:\n",
    "            total_time += params_data['dry_strategy_params']['pit_stop_time']\n",
    "            current_compound = pit_stops[lap_num]\n",
    "            last_pit_lap = lap_num\n",
    "\n",
    "        stint_length = lap_num - last_pit_lap\n",
    "        \n",
    "        # 랩타임 계산 (기존 로직과 거의 동일)\n",
    "        is_wet = row['rainfall'] > 0\n",
    "        params_key = 'wet_strategy_params' if is_wet and 'wet_strategy_params' in params_data else 'dry_strategy_params'\n",
    "        \n",
    "        if current_compound not in params_data[params_key]['compound_performance']:\n",
    "             params_key = 'dry_strategy_params' # Fallback\n",
    "             \n",
    "        perf = params_data[params_key]['compound_performance'][current_compound]\n",
    "        degradation = 1 + (perf[\"degradation_rate\"] * stint_length / 100)\n",
    "        adjusted_laptime = row['laptime'] * perf[\"base_pace\"] * degradation\n",
    "        total_time += adjusted_laptime\n",
    "        \n",
    "    return total_time\n",
    "\n",
    "def generate_candidate_strategies(total_laps):\n",
    "    \"\"\"총 랩 수를 바탕으로 1스톱, 2스톱 전략 후보들을 동적으로 생성합니다.\"\"\"\n",
    "    strategies = {}\n",
    "    \n",
    "    # --- 1-Stop 전략 후보 ---\n",
    "    # M -> H (가장 일반적)\n",
    "    pit_lap_1s_a = int(total_laps * 0.4)\n",
    "    strategies[f\"1-Stop (M-H, Lap {pit_lap_1s_a})\"] = [{'lap': pit_lap_1s_a, 'tyre': 'HARD'}]\n",
    "    \n",
    "    # S -> H (공격적)\n",
    "    pit_lap_1s_b = int(total_laps * 0.3)\n",
    "    strategies[f\"1-Stop (S-H, Lap {pit_lap_1s_b})\"] = [{'lap': pit_lap_1s_b, 'tyre': 'HARD'}]\n",
    "\n",
    "    # --- 2-Stop 전략 후보 ---\n",
    "    # S -> M -> M\n",
    "    pit_lap_2s_a1 = int(total_laps / 3)\n",
    "    pit_lap_2s_a2 = int(total_laps * 2 / 3)\n",
    "    strategies[f\"2-Stop (S-M-M, Laps {pit_lap_2s_a1}, {pit_lap_2s_a2})\"] = [\n",
    "        {'lap': pit_lap_2s_a1, 'tyre': 'MEDIUM'}, \n",
    "        {'lap': pit_lap_2s_a2, 'tyre': 'MEDIUM'}\n",
    "    ]\n",
    "    \n",
    "    # S -> M -> S\n",
    "    pit_lap_2s_b1 = int(total_laps * 0.25)\n",
    "    pit_lap_2s_b2 = int(total_laps * 0.65)\n",
    "    strategies[f\"2-Stop (S-M-S, Laps {pit_lap_2s_b1}, {pit_lap_2s_b2})\"] = [\n",
    "        {'lap': pit_lap_2s_b1, 'tyre': 'MEDIUM'},\n",
    "        {'lap': pit_lap_2s_b2, 'tyre': 'SOFT'}\n",
    "    ]\n",
    "    \n",
    "    return strategies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 목표 함수 정의\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 검색 공간\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'random_state': 42,\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "\n",
    "    # --- 다중 출력 모델 학습 (변환된 데이터 사용) ---\n",
    "    reg_param = param.copy()\n",
    "    reg_param['objective'] = 'reg:squarederror'\n",
    "    multi_output_model = xgb.XGBRegressor(**reg_param)\n",
    "    # X_train이 아닌 X_train_transformed를 사용\n",
    "    multi_output_model.fit(X_train_transformed, y_multi_train[:, [0, 2]])\n",
    "\n",
    "    # --- PitStop 분류 모델 학습 (변환 및 오버샘플링된 데이터 사용) ---\n",
    "    clf_param = param.copy()\n",
    "    clf_param['objective'] = 'binary:logistic'\n",
    "    clf_param['scale_pos_weight'] = trial.suggest_float('scale_pos_weight', 3, 5)\n",
    "    xgb_pitstop = xgb.XGBClassifier(**clf_param)\n",
    "    xgb_pitstop.fit(X_train_pit_res, y_pitstop_train_res)\n",
    "\n",
    "    # --- 예측 (변환된 테스트 데이터 사용) ---\n",
    "    y_pred_multi = multi_output_model.predict(X_test_transformed)\n",
    "    y_pred_pitstop_proba = xgb_pitstop.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "    # --- 평가 ---\n",
    "    y_pred_laptime = y_pred_multi[:, 0]\n",
    "    y_pred_tyrewear = y_pred_multi[:, 1] # XGBoost MultiOutput은 순서대로 출력하므로 인덱스 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_pitstop_test, y_pred_pitstop_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx] if len(thresholds) > 0 else 0.5\n",
    "    y_pred_pitstop = (y_pred_pitstop_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "    precision = precision_score(y_pitstop_test, y_pred_pitstop, zero_division=0)\n",
    "    f1 = f1_score(y_pitstop_test, y_pred_pitstop, zero_division=0)\n",
    "    r2_laptime = r2_score(y_laptime_test, y_pred_laptime)\n",
    "    r2_tyre_wear = r2_score(y_tyrewear_test, y_pred_tyrewear)\n",
    "    \n",
    "    # 가중치 합산 점수 반환\n",
    "    score = 0.4 * f1 + 0.2 * precision + 0.2 * r2_laptime + 0.2 * r2_tyre_wear\n",
    "    return score\n",
    "\n",
    "\n",
    "# --- 3. 적합도 평가 함수 (이전과 동일) ---\n",
    "def evaluate_hybrid_strategy(individual):\n",
    "    \"\"\"\n",
    "    GA가 제안한 전략(individual)의 '총 시간'과 '리스크'를 모두 평가합니다.\n",
    "    \"\"\"\n",
    "    MINIMUM_STINT_LAPS = 7  # 모든 스틴트의 최소 랩 수 (이 값은 조절 가능)\n",
    "\n",
    "\n",
    "    # 1. GA의 염색체를 시뮬레이션용 plan으로 변환\n",
    "    pit1_lap, pit1_tyre_idx, pit2_lap, pit2_tyre_idx = individual\n",
    "    plan = []\n",
    "    if pit1_lap > 0: plan.append({'lap': int(pit1_lap), 'tyre': COMPOUNDS[pit1_tyre_idx]})\n",
    "    if pit2_lap > 0: plan.append({'lap': int(pit2_lap), 'tyre': COMPOUNDS[pit2_tyre_idx]})\n",
    "    \n",
    "    # --- ⭐️ 여기가 핵심 수정 부분입니다 (최소 스틴트 길이 검사) ⭐️ ---\n",
    "    # 2. 모든 스틴트의 길이가 최소 기준을 만족하는지 검사\n",
    "    stint_lengths = []\n",
    "    last_pit_lap = 0\n",
    "    for pit in plan:\n",
    "        stint_lengths.append(pit['lap'] - last_pit_lap)\n",
    "        last_pit_lap = pit['lap']\n",
    "    stint_lengths.append(race_laps - last_pit_lap) # 마지막 스틴트\n",
    "\n",
    "    for length in stint_lengths:\n",
    "        if length < MINIMUM_STINT_LAPS:\n",
    "            # 스틴트 길이가 너무 짧으면 실격 처리 (아주 큰 페널티)\n",
    "            return (999999,)\n",
    "\n",
    "    # 2. F1의 '2가지 컴파운드 사용' 규정 검사\n",
    "    # (시작 타이어는 INITIAL_COMPOUND 변수를 사용한다고 가정)\n",
    "    compounds_used = {initial_compound}\n",
    "    for pit in plan:\n",
    "        compounds_used.add(pit['tyre'])\n",
    "    \n",
    "    # 사용된 컴파운드 종류가 2가지 미만이면 엄청난 페널티를 부여하고 즉시 반환\n",
    "    if len(compounds_used) < 2:\n",
    "        # 이 전략은 실격(Disqualified)이므로, 아주 큰 시간(페널티)을 반환하여 도태시킴\n",
    "        return (999999,) \n",
    "\n",
    "\n",
    "    # 2. '총 레이스 시간' 계산 (기존과 동일)\n",
    "    # evaluate_strategy 함수는 이제 '헬퍼' 함수가 됩니다.\n",
    "    total_time = evaluate_strategy(lap_data_df, params_data, plan, initial_compound, race_laps)\n",
    "\n",
    "    # 3. '리스크 패널티' 계산 (반응형 모델 인수 사용)\n",
    "    risk_penalty = 0\n",
    "    dry_params = params_data['dry_strategy_params'] # 결정용 파라미터 로드\n",
    "    \n",
    "    for pit_stop in plan:\n",
    "        pit_lap = pit_stop['lap']\n",
    "        \n",
    "        # 해당 랩의 데이터(ML 예측치) 가져오기\n",
    "        lap_info = lap_data_df[lap_data_df['lap'] == pit_lap]\n",
    "        if not lap_info.empty:\n",
    "            wear_at_pit = lap_info.iloc[0]['tyre_wear']\n",
    "            proba_at_pit = lap_info.iloc[0]['pit_proba']\n",
    "\n",
    "            # 패널티 조건 1: 타이어를 너무 한계까지 몰아붙인 전략에 큰 패널티\n",
    "            if wear_at_pit > dry_params['TyreLife_threshold'] * 1.5: # 임계값의 150% 초과 시\n",
    "                penalty = (wear_at_pit - dry_params['TyreLife_threshold']) * 5 # 초과한 만큼 큰 패널티\n",
    "                risk_penalty += penalty\n",
    "                print(f\"DEBUG: Lap {pit_lap} - High Wear Penalty! Wear:{wear_at_pit:.1f} -> Penalty:{penalty:.1f}s\")\n",
    "\n",
    "            # 패널티 조건 2: ML모델이 전혀 피트인을 예측하지 않은 랩에 들어가는 전략에 작은 패널티\n",
    "            if proba_at_pit < dry_params['pit_proba_threshold'] * 0.1: # 임계값의 10% 미만 시\n",
    "                penalty = 10 # 10초 고정 패널티\n",
    "                risk_penalty += penalty\n",
    "                print(f\"DEBUG: Lap {pit_lap} - Low Proba Penalty! Proba:{proba_at_pit:.2f} -> Penalty:{penalty:.1f}s\")\n",
    "\n",
    "    # 최종 적합도 = 총 시간 + 리스크 패널티\n",
    "    final_score = total_time + risk_penalty\n",
    "    return (final_score,) # DEAP는 튜플로 반환해야 함\n",
    "\n",
    "\n",
    "def create_random_strategy(race_laps):\n",
    "    num_stops = random.randint(1, 2)\n",
    "    \n",
    "    if num_stops == 1:\n",
    "        pit1_lap = random.randint(10, race_laps - 10)\n",
    "        pit1_tyre = random.randint(0, 2)\n",
    "        # ⭐️ 그냥 리스트가 아닌, creator.Individual로 감싸서 반환\n",
    "        return creator.Individual([pit1_lap, pit1_tyre, 0, 0]) \n",
    "    else: # 2 stops\n",
    "        pit1_lap = random.randint(10, int(race_laps / 2))\n",
    "        pit2_lap = random.randint(pit1_lap + 10, race_laps - 10)\n",
    "        pit1_tyre = random.randint(0, 2)\n",
    "        pit2_tyre = random.randint(0, 2)\n",
    "        # ⭐️ 여기도 creator.Individual로 감싸서 반환\n",
    "        return creator.Individual([pit1_lap, pit1_tyre, pit2_lap, pit2_tyre])\n",
    "\n",
    "# --- 4. ⭐️ 규칙을 준수하는 스마트한 교배, 돌연변이, 선택 연산자 정의 ⭐️ ---\n",
    "def custom_mutate(individual, low, up, indpb):\n",
    "    # DEAP의 기본 돌연변이 함수를 먼저 실행\n",
    "    tools.mutUniformInt(individual, low, up, indpb)\n",
    "    # ⭐️ 핵심 수정: 두 피트스톱 랩이 같아지는 경우를 처리하는 로직 추가 ⭐️\n",
    "    if individual[2] > 0: # 2스톱 전략일 경우에만 검사\n",
    "        if individual[0] == individual[2]:\n",
    "            # 두 랩이 같으면, 비현실적이므로 2스톱을 1스톱으로 변경\n",
    "            individual[2] = 0\n",
    "            individual[3] = 0\n",
    "        elif individual[0] > individual[2]:\n",
    "            # 순서가 어긋났으면 바로잡음\n",
    "            individual[0], individual[2] = individual[2], individual[0]\n",
    "    return individual, # 튜플로 반환해야 함\n",
    "\n",
    "def custom_mate(ind1, ind2):\n",
    "    # DEAP의 기본 교배 함수를 먼저 실행\n",
    "    tools.cxTwoPoint(ind1, ind2)\n",
    "    # ⭐️ 핵심 수정: 교배 후 생성된 두 자식 전략 모두에 대해 검사 ⭐️\n",
    "    for ind in [ind1, ind2]:\n",
    "        if ind[2] > 0: # 2스톱 전략일 경우에만 검사\n",
    "            if ind[0] == ind[2]:\n",
    "                # 두 랩이 같으면, 1스톱으로 변경\n",
    "                ind[2] = 0\n",
    "                ind[3] = 0\n",
    "            elif ind[0] > ind[2]:\n",
    "                # 순서가 어긋났으면 바로잡음\n",
    "                ind[0], ind[2] = ind[2], ind[0]\n",
    "    return ind1, ind2\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# [ STEP 3: 데이터 및 파라미터 로딩 ]\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "track = [\n",
    "    \"Eifel\",\n",
    "    \"Emilia_Romagna\",\n",
    "    \"French\",\n",
    "    \"German\",\n",
    "    \"Hungarian\",\n",
    "    \"Italian\",\n",
    "    \"Japanese\",\n",
    "    \"Las_Vegas\",\n",
    "    \"Mexico_City\",\n",
    "    \"Miami\",\n",
    "    \"Monaco\",\n",
    "    \"Portuguese\",\n",
    "    \"Qatar\",\n",
    "    \"Russian\",\n",
    "    \"Sakhir\",\n",
    "    \"Saudi_Arabian\",\n",
    "    \"Singapore\",\n",
    "    \"Spanish\",\n",
    "    \"Styrian\",\n",
    "    \"Sao_Paulo\",\n",
    "    \"Turkish\",\n",
    "    \"Tuscan\",\n",
    "    \"United_States\"\n",
    "]\n",
    "compound = [\"HARD\", \"MEDIUM\", \"SOFT\"]\n",
    "\n",
    "# track_name = 'Australian' # <--- 분석하고 싶은 트랙 이름만 여기서 변경하세요.\n",
    "# initial_compound = \"D\" # 시뮬레이션 시작 타이어 (필요시 변경)\n",
    "\n",
    "for track_name in track :\n",
    "\n",
    "\n",
    "    print(f\">>> STEP 3: '{track_name}' 데이터 및 파라미터 로딩 시작...\")\n",
    "\n",
    "    # 트랙 설정 파일 로드\n",
    "    with open('/home/azureuser/cloudfiles/code/Users/data/tracks_config.json', 'r', encoding='utf-8') as f:\n",
    "        tracks_config = json.load(f)\n",
    "    if track_name not in tracks_config:\n",
    "        raise ValueError(f\"'{track_name}' 설정이 'tracks_config.json'에 없습니다.\")\n",
    "\n",
    "    # 타겟 트랙의 정보 추출\n",
    "    track_info = tracks_config[track_name]\n",
    "    race_laps = track_info['total_laps']\n",
    "    target_group = track_info.get('group') # 타겟 트랙의 그룹 이름 가져오기\n",
    "\n",
    "    # grand_prix_list 생성\n",
    "    grand_prix_list = []\n",
    "    if target_group:\n",
    "        print(f\"'{track_name}' 트랙은 '{target_group}' 그룹에 속합니다. 그룹 전체 데이터를 로드합니다.\")\n",
    "        # 전체 설정 파일에서 같은 그룹에 속한 모든 트랙을 찾음\n",
    "        for t_name, t_info in tracks_config.items():\n",
    "            if t_info.get('group') == target_group:\n",
    "                grand_prix_list.extend(t_info['data_files']) # 해당 트랙의 데이터 파일 목록을 추가\n",
    "    else:\n",
    "        # 그룹이 지정되지 않은 경우, 해당 트랙의 데이터만 사용\n",
    "        print(f\"'{track_name}' 트랙에 그룹이 지정되지 않았습니다. 단일 트랙 데이터만 로드합니다.\")\n",
    "        grand_prix_list = track_info['data_files']\n",
    "\n",
    "    print(f\"데이터 로딩 대상: {grand_prix_list}\")\n",
    "\n",
    "\n",
    "    # Azure Blob Storage 설정\n",
    "    azure_access = AzureStorageAccess()\n",
    "    # 모든 파일 순회하고 싶다.\n",
    "    # for file in azure_access.get_all_file():\n",
    "    #     file_name = file.name\n",
    "    #     data_frame = azure_access.get_file_by_data_frame(file_name)   <- 지금 돌고있는 파일블롭을 바로 데이터로 변환\n",
    "\n",
    "    #       data_frame = azure_access.read_csv_by_data_frame(file_name) <- 지금 돌고있는 파일블롭의 이름을 뽑아서 다시 파일 전부 돌아가며 이름과 똑같은 파일찾아서 반환\n",
    "\n",
    "\n",
    "    all_laps_data = []\n",
    "    all_weather_data = []\n",
    "\n",
    "    compound_map = {\n",
    "        'SOFT': 'SOFT',\n",
    "        'SUPERSOFT': 'SOFT',\n",
    "        'ULTRASOFT': 'SOFT',\n",
    "        'HYPERSOFT': 'SOFT',\n",
    "        'MEDIUM': 'MEDIUM',\n",
    "        'HARD': 'HARD',\n",
    "        'INTERMEDIATE': 'INTERMEDIATE',   # 비건조\n",
    "        'WET': 'WET',                     # 비건조\n",
    "        'TEST': 'TEST',\n",
    "        'TEST_UNKNOWN': 'Unknown',\n",
    "        'UNKNOWN': 'Unknown'\n",
    "    }\n",
    "\n",
    "    for gp in grand_prix_list:\n",
    "        session_info = azure_access.read_csv_by_data_frame(f'{gp}/session_info.csv')\n",
    "        if session_info is not None:\n",
    "            print(f\"Loaded {gp}/session_info.csv with columns: {session_info.columns.tolist()}\")\n",
    "            base_time = pd.to_datetime(session_info[session_info['Type'] == 'Race']['StartDate'].iloc[0])\n",
    "        else:\n",
    "            year = gp.split('/')[0]\n",
    "            base_time = pd.to_datetime(f'{year}-12-08 14:00:00')\n",
    "            print(f\"Warning: Failed to load {gp}/session_info.csv, using default base_time: {base_time}\")\n",
    "        \n",
    "        laps_data = azure_access.read_csv_by_data_frame(f'{gp}/laps.csv')\n",
    "        if laps_data is not None:\n",
    "            print(f\"Loaded {gp}/laps.csv with columns: {laps_data.columns.tolist()}\")\n",
    "            laps_data['Time'] = pd.to_timedelta(laps_data['Time'].astype(str).str.replace('0 days', '').str.strip())\n",
    "            laps_data['Time'] = base_time + laps_data['Time']\n",
    "            laps_data['GrandPrix'] = gp\n",
    "            if 'Compound' in laps_data.columns:\n",
    "                laps_data['Compound'] = laps_data['Compound'].replace(compound_map)\n",
    "                # 제거할 Compound 목록\n",
    "                drop_compounds = ['TEST', 'TEST_UNKNOWN', 'UNKNOWN']\n",
    "                # 해당 Compound인 행 제거\n",
    "                laps_data = laps_data[~laps_data['Compound'].isin(drop_compounds)].reset_index(drop=True)\n",
    "            else:\n",
    "                print(f\"Warning: No 'Compound' column in {gp}/laps.csv, skipping compound processing\")\n",
    "            all_laps_data.append(laps_data)  # 항상 추가\n",
    "        else:\n",
    "            print(f\"Warning: Failed to load {gp}/laps.csv\")\n",
    "\n",
    "        weather_data = azure_access.read_csv_by_data_frame(f'{gp}/weather_data.csv')\n",
    "        if weather_data is not None:\n",
    "            print(f\"Loaded {gp}/weather_data.csv with columns: {weather_data.columns.tolist()}\")\n",
    "            weather_data['Time'] = pd.to_timedelta(weather_data['Time'].astype(str).str.replace('0 days', '').str.strip())\n",
    "            weather_data['Time'] = base_time + weather_data['Time']\n",
    "            weather_data['GrandPrix'] = gp\n",
    "            weather_data = weather_data.sort_values('Time')\n",
    "            all_weather_data.append(weather_data)\n",
    "        else:\n",
    "            print(f\"Warning: Failed to load {gp}/weather_data.csv\")\n",
    "\n",
    "    # 데이터 결합\n",
    "    laps_data = pd.concat(all_laps_data, ignore_index=True)\n",
    "\n",
    "    # --- 이 코드를 데이터 로딩 및 결합 직후에 추가하세요 ---\n",
    "\n",
    "    print(f\"처리 전 데이터 행 수: {len(laps_data)}\")\n",
    "    print(f\"처리 전 'Unknown' 데이터 수: {len(laps_data[laps_data['Compound'] == 'Unknown'])}\")\n",
    "\n",
    "    # 'Compound' 컬럼 값이 'Unknown'이 아닌 행들만 남깁니다.\n",
    "    laps_data = laps_data[laps_data['Compound'] != 'Unknown'].reset_index(drop=True)\n",
    "\n",
    "    print(f\"처리 후 'Unknown' 데이터 수: {len(laps_data[laps_data['Compound'] == 'Unknown'])}\")\n",
    "    print(f\"처리 후 데이터 행 수: {len(laps_data)}\")\n",
    "\n",
    "    weather_data = pd.concat(all_weather_data, ignore_index=True)\n",
    "\n",
    "    if not weather_data.empty:\n",
    "        print(f\"Loaded weather.csv with columns: {weather_data.columns.tolist()}\")\n",
    "\n",
    "    print(\"laps_data shape:\", laps_data.shape)\n",
    "    print(\"laps_data columns:\", laps_data.columns)\n",
    "    print(\"Sample PitInTime and PitOutTime:\\n\", laps_data[['LapNumber', 'PitInTime', 'PitOutTime']].head(30))\n",
    "\n",
    "    # 데이터 전처리 및 정렬 (수정된 부분)\n",
    "    def fix_time_sorting(df, time_col='Time', group_col='GrandPrix'):\n",
    "        \"\"\"\n",
    "        시간 컬럼의 정렬 문제를 수정하는 함수\n",
    "        \"\"\"\n",
    "        # NaN 값 제거\n",
    "        df = df.dropna(subset=[time_col]).copy()\n",
    "        \n",
    "        # datetime으로 변환\n",
    "        df[time_col] = pd.to_datetime(df[time_col])\n",
    "        \n",
    "        # 각 그룹별로 정렬 확인 및 수정\n",
    "        fixed_groups = []\n",
    "        \n",
    "        for group_name in df[group_col].unique():\n",
    "            group_data = df[df[group_col] == group_name].copy()\n",
    "            \n",
    "            # 시간순으로 정렬\n",
    "            group_data = group_data.sort_values(time_col).reset_index(drop=True)\n",
    "            \n",
    "            # 정렬 확인\n",
    "            if not group_data[time_col].is_monotonic_increasing:\n",
    "                print(f\"Warning: {group_name} has non-monotonic time values, fixing...\")\n",
    "                # 중복된 시간값이 있을 경우 미세하게 조정\n",
    "                duplicated = group_data[time_col].duplicated()\n",
    "                if duplicated.any():\n",
    "                    print(f\"Found {duplicated.sum()} duplicate time values in {group_name}\")\n",
    "                    # 중복된 시간에 microsecond 추가\n",
    "                    for i, is_dup in enumerate(duplicated):\n",
    "                        if is_dup:\n",
    "                            group_data.iloc[i, group_data.columns.get_loc(time_col)] += pd.Timedelta(microseconds=i)\n",
    "            \n",
    "            fixed_groups.append(group_data)\n",
    "            print(f\"Fixed {group_name}: {len(group_data)} rows, time range: {group_data[time_col].min()} to {group_data[time_col].max()}\")\n",
    "        \n",
    "        return pd.concat(fixed_groups, ignore_index=True)\n",
    "\n",
    "    # 시간 정렬 수정\n",
    "    print(\"\\n=== Fixing time sorting issues ===\")\n",
    "    laps_data = fix_time_sorting(laps_data)\n",
    "    weather_data = fix_time_sorting(weather_data)\n",
    "\n",
    "    # 병합 전 최종 정렬 및 확인\n",
    "    print(\"\\n=== Final sorting and verification ===\")\n",
    "    laps_data = laps_data.sort_values(['GrandPrix', 'Time']).reset_index(drop=True)\n",
    "    weather_data = weather_data.sort_values(['GrandPrix', 'Time']).reset_index(drop=True)\n",
    "\n",
    "    # 정렬 상태 최종 확인\n",
    "    print(\"Final sorting verification:\")\n",
    "    for gp in laps_data['GrandPrix'].unique():\n",
    "        laps_gp = laps_data[laps_data['GrandPrix'] == gp]['Time']\n",
    "        weather_gp = weather_data[weather_data['GrandPrix'] == gp]['Time'] if gp in weather_data['GrandPrix'].unique() else pd.Series(dtype='datetime64[ns]')\n",
    "        \n",
    "        laps_sorted = laps_gp.is_monotonic_increasing\n",
    "        weather_sorted = weather_gp.is_monotonic_increasing if not weather_gp.empty else True\n",
    "        \n",
    "        print(f\"{gp}: laps_sorted={laps_sorted}, weather_sorted={weather_sorted}\")\n",
    "        \n",
    "        if not laps_sorted or not weather_sorted:\n",
    "            print(f\"ERROR: {gp} is not properly sorted!\")\n",
    "            break\n",
    "\n",
    "    # 시간 차이 계산 (수정)\n",
    "    print(\"\\n=== Analyzing time differences ===\")\n",
    "    laps_times = laps_data.sort_values(['GrandPrix', 'Time'])['Time']\n",
    "    weather_times = weather_data.sort_values(['GrandPrix', 'Time'])['Time']\n",
    "    time_diff = pd.Series(dtype='timedelta64[ns]', index=laps_times.index)\n",
    "    for idx in laps_times.index:\n",
    "        nearest_idx = weather_times.searchsorted(laps_times[idx], side='left') - 1\n",
    "        if nearest_idx >= 0 and nearest_idx < len(weather_times):\n",
    "            nearest_weather_time = weather_times.iloc[nearest_idx]\n",
    "            time_diff[idx] = abs(laps_times[idx] - nearest_weather_time)\n",
    "        else:\n",
    "            time_diff[idx] = pd.Timedelta(seconds=0)  # 기본값 설정\n",
    "    print(f\"Max time difference: {time_diff.max()}\")\n",
    "    print(f\"Mean time difference: {time_diff[time_diff > pd.Timedelta(0)].mean().total_seconds():.2f} seconds\")\n",
    "    print(f\"Median time difference: {time_diff[time_diff > pd.Timedelta(0)].median().total_seconds():.2f} seconds\")\n",
    "\n",
    "    # Fixed merge section - replace the existing merge attempt section\n",
    "\n",
    "    print(\"\\n=== Attempting merge (FIXED) ===\")\n",
    "\n",
    "    # Check if we have weather data to merge\n",
    "    if not weather_data.empty:\n",
    "        # Create separate dataframes for each Grand Prix and merge individually\n",
    "        merged_groups = []\n",
    "        \n",
    "        for gp in laps_data['GrandPrix'].unique():\n",
    "            print(f\"Processing {gp}...\")\n",
    "            \n",
    "            # Get data for this specific Grand Prix\n",
    "            laps_gp = laps_data[laps_data['GrandPrix'] == gp].copy()\n",
    "            weather_gp = weather_data[weather_data['GrandPrix'] == gp].copy()\n",
    "            \n",
    "            if weather_gp.empty:\n",
    "                print(f\"  No weather data for {gp}, using default values\")\n",
    "                # Add default weather values\n",
    "                if not weather_data.empty:\n",
    "                    avg_track_temp = weather_data['TrackTemp'].mean()\n",
    "                    avg_air_temp = weather_data['AirTemp'].mean() if 'AirTemp' in weather_data.columns else 25.0\n",
    "                    laps_gp['TrackTemp'] = avg_track_temp\n",
    "                    if 'AirTemp' in weather_data.columns:\n",
    "                        laps_gp['AirTemp'] = avg_air_temp\n",
    "                    if 'Humidity' in weather_data.columns:\n",
    "                        laps_gp['Humidity'] = weather_data['Humidity'].mean()\n",
    "                    if 'Pressure' in weather_data.columns:\n",
    "                        laps_gp['Pressure'] = weather_data['Pressure'].mean()\n",
    "                    if 'WindDirection' in weather_data.columns:\n",
    "                        laps_gp['WindDirection'] = weather_data['WindDirection'].mean()\n",
    "                    if 'WindSpeed' in weather_data.columns:\n",
    "                        laps_gp['WindSpeed'] = weather_data['WindSpeed'].mean()\n",
    "                    if 'Rainfall' in weather_data.columns:\n",
    "                        laps_gp['Rainfall'] = 0\n",
    "                merged_groups.append(laps_gp)\n",
    "                continue\n",
    "            \n",
    "            # Sort by Time only (critical for merge_asof)\n",
    "            laps_gp = laps_gp.sort_values('Time').reset_index(drop=True)\n",
    "            weather_gp = weather_gp.sort_values('Time').reset_index(drop=True)\n",
    "            \n",
    "            # Verify sorting\n",
    "            if not laps_gp['Time'].is_monotonic_increasing:\n",
    "                print(f\"  ERROR: laps data for {gp} is not properly time-sorted\")\n",
    "                continue\n",
    "            if not weather_gp['Time'].is_monotonic_increasing:\n",
    "                print(f\"  ERROR: weather data for {gp} is not properly time-sorted\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Perform merge_asof for this Grand Prix\n",
    "                merged_gp = pd.merge_asof(\n",
    "                    laps_gp,\n",
    "                    weather_gp.drop(columns=['GrandPrix']),  # Remove GrandPrix to avoid duplication\n",
    "                    on='Time',\n",
    "                    direction='nearest',\n",
    "                    tolerance=pd.Timedelta(minutes=20)  # 20 minute tolerance\n",
    "                )\n",
    "                \n",
    "                print(f\"  Successfully merged {len(merged_gp)} rows\")\n",
    "                merged_groups.append(merged_gp)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Merge failed for {gp}: {e}\")\n",
    "                # Add default weather values for this GP\n",
    "                if not weather_data.empty:\n",
    "                    avg_track_temp = weather_data['TrackTemp'].mean()\n",
    "                    laps_gp['TrackTemp'] = avg_track_temp\n",
    "                    if 'AirTemp' in weather_data.columns:\n",
    "                        laps_gp['AirTemp'] = weather_data['AirTemp'].mean()\n",
    "                merged_groups.append(laps_gp)\n",
    "        \n",
    "        # Combine all merged groups\n",
    "        if merged_groups:\n",
    "            laps_data = pd.concat(merged_groups, ignore_index=True)\n",
    "            print(\"Merge completed successfully!\")\n",
    "            print(f\"Final merged data shape: {laps_data.shape}\")\n",
    "            \n",
    "            # Check what weather columns were successfully merged\n",
    "            weather_cols = ['TrackTemp', 'AirTemp', 'Humidity', 'Pressure', 'WindDirection', 'WindSpeed', 'Rainfall']\n",
    "            available_weather_cols = [col for col in weather_cols if col in laps_data.columns]\n",
    "            print(f\"Available weather columns: {available_weather_cols}\")\n",
    "            \n",
    "            # Show weather data statistics\n",
    "            for col in available_weather_cols:\n",
    "                if laps_data[col].notna().sum() > 0:\n",
    "                    print(f\"  {col}: {laps_data[col].min():.1f} to {laps_data[col].max():.1f} (mean: {laps_data[col].mean():.1f})\")\n",
    "        else:\n",
    "            print(\"No data groups were successfully processed\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No weather data available for merging\")\n",
    "        # Add default weather columns\n",
    "        laps_data['TrackTemp'] = 31.2  # Default track temperature\n",
    "        laps_data['AirTemp'] = 25.0    # Default air temperature\n",
    "\n",
    "    print(f\"Final data shape after merge: {laps_data.shape}\")\n",
    "    print(f\"Columns after merge: {laps_data.columns.tolist()}\")\n",
    "\n",
    "    # 나머지 전처리\n",
    "    print(\"\\n=== Data preprocessing ===\")\n",
    "\n",
    "    # Boolean 열 처리\n",
    "    boolean_cols = ['IsPersonalBest', 'FreshTyre', 'Deleted', 'FastF1Generated', 'IsAccurate']\n",
    "    if 'Rainfall' in laps_data.columns:\n",
    "        boolean_cols.append('Rainfall')\n",
    "\n",
    "    for col in boolean_cols:\n",
    "        if col in laps_data.columns:\n",
    "            laps_data[col] = pd.to_numeric(laps_data[col], errors='coerce').fillna(0).astype('Int64')\n",
    "\n",
    "    # Special handling for pit-related columns\n",
    "    laps_data['IsPitStop'] = laps_data['PitInTime'].notnull().astype('Int64')\n",
    "\n",
    "    # 'LapTime' 및 섹터 타임 변환\n",
    "    time_cols = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']\n",
    "    for col in time_cols:\n",
    "        if col in laps_data.columns and laps_data[col].dtype != 'float64':\n",
    "            laps_data[col] = laps_data[col].apply(lambda x: pd.to_timedelta(str(x).replace('0 days', '')).total_seconds() if pd.notna(x) else np.nan)\n",
    "\n",
    "    # Drop rows where 'LapTime' is missing\n",
    "    laps_data = laps_data.dropna(subset=['LapTime', 'Compound', 'TyreLife'])\n",
    "\n",
    "    # SpeedI1, SpeedFL 보간\n",
    "    if 'SpeedI1' in laps_data.columns:\n",
    "        laps_data['SpeedI1'] = laps_data['SpeedI1'].interpolate(method='linear').fillna(laps_data['SpeedI1'].median())\n",
    "    if 'SpeedFL' in laps_data.columns:\n",
    "        laps_data['SpeedFL'] = laps_data['SpeedFL'].interpolate(method='linear').fillna(laps_data['SpeedFL'].median())\n",
    "\n",
    "    # 피처 엔지니어링: 타이어 마모율\n",
    "    laps_data['TyreWear'] = laps_data.groupby(['Driver', 'Stint'])['TyreLife'].transform('max') - laps_data['TyreLife']\n",
    "\n",
    "    # 피처 엔지니어링: LapTime 변화율\n",
    "    laps_data['LapTime_Delta'] = laps_data.groupby(['Driver', 'Stint'])['LapTime'].diff().fillna(0)\n",
    "    if 'SpeedI1' in laps_data.columns:\n",
    "        laps_data['SpeedI1_Delta'] = laps_data.groupby(['Driver', 'Stint'])['SpeedI1'].diff().fillna(0)\n",
    "    laps_data['TyreWear_Rate'] = laps_data.groupby(['Driver', 'Stint'])['TyreWear'].diff().fillna(0) / laps_data['LapNumber']\n",
    "\n",
    "    # Define column categories\n",
    "    numerical_cols = ['LapNumber', 'Stint', 'TyreLife', 'Position', 'LapTime_Delta', 'TyreWear_Rate']\n",
    "    if 'SpeedI1' in laps_data.columns:\n",
    "        numerical_cols.extend(['SpeedI1', 'SpeedI1_Delta'])\n",
    "    if 'SpeedFL' in laps_data.columns:\n",
    "        numerical_cols.append('SpeedFL')\n",
    "    if 'TrackTemp' in laps_data.columns:\n",
    "        numerical_cols.append('TrackTemp')\n",
    "    if 'AirTemp' in laps_data.columns:\n",
    "        numerical_cols.append('AirTemp')\n",
    "    if 'Rainfall' in laps_data.columns:\n",
    "        numerical_cols.append('Rainfall')\n",
    "\n",
    "    categorical_cols = ['Compound', 'Driver', 'Team']\n",
    "    if 'TrackStatus' in laps_data.columns:\n",
    "        categorical_cols.append('TrackStatus')\n",
    "\n",
    "    # Boolean 열 처리 (존재하는 컬럼만)\n",
    "    boolean_cols_candidate = ['IsPersonalBest', 'FreshTyre', 'Deleted', 'FastF1Generated', 'IsAccurate', 'Rainfall']\n",
    "    boolean_cols = [col for col in boolean_cols_candidate if col in laps_data.columns]\n",
    "\n",
    "    print(f\"Processing boolean columns: {boolean_cols}\")\n",
    "    for col in boolean_cols:\n",
    "        # NaN을 0으로 대체하고 nullable 정수형으로 변환\n",
    "        laps_data[col] = pd.to_numeric(laps_data[col], errors='coerce').fillna(0).astype('Int64')\n",
    "\n",
    "    # Special handling for pit-related columns\n",
    "    laps_data['IsPitStop'] = laps_data['PitInTime'].notnull().astype('Int64')\n",
    "    print(\"Created IsPitStop column\")\n",
    "\n",
    "    # 'LapTime' 및 섹터 타임 변환\n",
    "    time_cols_candidate = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']\n",
    "    time_cols = [col for col in time_cols_candidate if col in laps_data.columns]\n",
    "\n",
    "    print(f\"Processing time columns: {time_cols}\")\n",
    "    for col in time_cols:\n",
    "        if laps_data[col].dtype != 'float64':\n",
    "            print(f\"Converting {col} from {laps_data[col].dtype} to seconds\")\n",
    "            laps_data[col] = laps_data[col].apply(\n",
    "                lambda x: pd.to_timedelta(str(x).replace('0 days', '')).total_seconds() \n",
    "                if pd.notna(x) else np.nan\n",
    "            )\n",
    "\n",
    "    # Drop rows where 'LapTime' is missing\n",
    "    if 'LapTime' in laps_data.columns:\n",
    "        before_drop = len(laps_data)\n",
    "        laps_data = laps_data.dropna(subset=['LapTime'])\n",
    "        after_drop = len(laps_data)\n",
    "        print(f\"Dropped {before_drop - after_drop} rows with missing LapTime\")\n",
    "\n",
    "    # SpeedI1, SpeedFL 보간 (존재하는 컬럼만)\n",
    "    speed_cols = ['SpeedI1', 'SpeedFL', 'SpeedI2', 'SpeedST']\n",
    "    for col in speed_cols:\n",
    "        if col in laps_data.columns:\n",
    "            print(f\"Interpolating {col}\")\n",
    "            laps_data[col] = laps_data[col].interpolate(method='linear').fillna(laps_data[col].median())\n",
    "\n",
    "    # 피처 엔지니어링: 타이어 마모율\n",
    "    if all(col in laps_data.columns for col in ['Driver', 'Stint', 'TyreLife']):\n",
    "        laps_data['TyreWear'] = laps_data.groupby(['Driver', 'Stint'])['TyreLife'].transform('max') - laps_data['TyreLife']\n",
    "        print(\"Created TyreWear feature\")\n",
    "\n",
    "    # 피처 엔지니어링: LapTime 변화율\n",
    "    if all(col in laps_data.columns for col in ['Driver', 'Stint', 'LapTime']):\n",
    "        laps_data['LapTime_Delta'] = laps_data.groupby(['Driver', 'Stint'])['LapTime'].diff().fillna(0)\n",
    "        print(\"Created LapTime_Delta feature\")\n",
    "\n",
    "    if all(col in laps_data.columns for col in ['Driver', 'Stint', 'SpeedI1']):\n",
    "        laps_data['SpeedI1_Delta'] = laps_data.groupby(['Driver', 'Stint'])['SpeedI1'].diff().fillna(0)\n",
    "        print(\"Created SpeedI1_Delta feature\")\n",
    "\n",
    "    if all(col in laps_data.columns for col in ['Driver', 'Stint', 'TyreWear', 'LapNumber']):\n",
    "        laps_data['TyreWear_Rate'] = laps_data.groupby(['Driver', 'Stint'])['TyreWear'].diff().fillna(0) / laps_data['LapNumber']\n",
    "        print(\"Created TyreWear_Rate feature\")\n",
    "\n",
    "    # Define column categories (존재하는 컬럼만)\n",
    "    numerical_cols_candidate = [\n",
    "        'LapNumber', 'Stint', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', \n",
    "        'TyreLife', 'Position', 'TrackTemp', 'AirTemp', 'Humidity', 'Pressure', 'WindDirection', 'WindSpeed',\n",
    "        'LapTime_Delta', 'SpeedI1_Delta', 'TyreWear_Rate', 'TyreWear', 'Rainfall'\n",
    "    ]\n",
    "    numerical_cols = [col for col in numerical_cols_candidate if col in laps_data.columns]\n",
    "\n",
    "    categorical_cols_candidate = ['Compound', 'TrackStatus', 'Driver', 'Team', 'DriverNumber']\n",
    "    categorical_cols = [col for col in categorical_cols_candidate if col in laps_data.columns]\n",
    "\n",
    "    print(f\"\\nFinal column categories:\")\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "    # 데이터 품질 체크\n",
    "    print(f\"\\nData quality check:\")\n",
    "    print(f\"Total rows: {len(laps_data)}\")\n",
    "    print(f\"Total columns: {len(laps_data.columns)}\")\n",
    "\n",
    "    # Missing values check for key columns\n",
    "    key_columns = ['LapTime', 'Driver', 'LapNumber', 'GrandPrix', 'Compound', 'TyreLife']\n",
    "    for col in key_columns:\n",
    "        if col in laps_data.columns:\n",
    "            missing_count = laps_data[col].isnull().sum()\n",
    "            print(f\"{col}: {missing_count} missing values ({missing_count/len(laps_data)*100:.2f}%)\")\n",
    "\n",
    "    # PitStop 관련 통계\n",
    "    if 'IsPitStop' in laps_data.columns:\n",
    "        pit_stops = laps_data[laps_data['IsPitStop'] == 1]\n",
    "        print(f\"\\nPit stop statistics:\")\n",
    "        print(f\"Total pit stops: {len(pit_stops)}\")\n",
    "        print(f\"Pit stops with PitInTime: {pit_stops['PitInTime'].notna().sum()}\")\n",
    "        print(f\"Pit stops with PitOutTime: {pit_stops['PitOutTime'].notna().sum()}\")\n",
    "\n",
    "    # GrandPrix별 데이터 분포\n",
    "    if 'GrandPrix' in laps_data.columns:\n",
    "        print(f\"\\nData distribution by GrandPrix:\")\n",
    "        gp_counts = laps_data['GrandPrix'].value_counts()\n",
    "        for gp, count in gp_counts.items():\n",
    "            print(f\"  {gp}: {count} rows\")\n",
    "\n",
    "\n",
    "    print(\"\\nData preprocessing completed successfully!\")\n",
    "\n",
    "    print(\"\\nPHASE 2: 데이터셋 분리 시작\")\n",
    "    laps_data_grouped = laps_data.copy()\n",
    "    laps_data_single = laps_data[laps_data['GrandPrix'].str.contains(track_name, na=False)].copy()\n",
    "\n",
    "    dry_laps_data_grouped = laps_data_grouped[laps_data_grouped['Rainfall'] == 0].copy()\n",
    "    wet_laps_data_grouped = laps_data_grouped[laps_data_grouped['Rainfall'] == 1].copy()\n",
    "    dry_laps_data_single = laps_data_single[laps_data_single['Rainfall'] == 0].copy()\n",
    "\n",
    "    has_wet_data = not wet_laps_data_grouped.empty\n",
    "    print(\"PHASE 2: 완료\")\n",
    "\n",
    "\n",
    "\n",
    "    train_data = dry_laps_data_grouped.copy()\n",
    "\n",
    "    # preprocessor 정의\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]), numerical_cols),\n",
    "            ('cat', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # handle_unknown 추가\n",
    "            ]), categorical_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    # 타겟 변수 설정\n",
    "    X = train_data[numerical_cols + categorical_cols]\n",
    "    y_laptime = train_data['LapTime'].values\n",
    "    y_pitstop = (train_data['PitInTime'].notna()).astype(int).values\n",
    "    y_tyrewear = train_data['TyreWear'].values\n",
    "    y_multi = np.column_stack((y_laptime, y_pitstop, y_tyrewear))\n",
    "\n",
    "\n",
    "    # --- 3. 데이터 분할 ---\n",
    "    X_train, X_test, y_multi_train, y_multi_test = train_test_split(\n",
    "        X, y_multi, test_size=0.2, random_state=42\n",
    "    )\n",
    "    y_laptime_train, y_pitstop_train, y_tyrewear_train = y_multi_train.T\n",
    "    y_laptime_test, y_pitstop_test, y_tyrewear_test = y_multi_test.T\n",
    "\n",
    "\n",
    "    # ==============================================================================\n",
    "    # ⭐️ 찾은 최적 파라미터로 최종 모델 학습 (수정된 최종 버전) ⭐️\n",
    "    # ==============================================================================\n",
    "\n",
    "    # preprocessor 학습\n",
    "    preprocessor.fit(X_train)\n",
    "\n",
    "    X_train_transformed = preprocessor.transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # 5. 오버샘플링 (ADASYN) - 변환된 데이터를 사용\n",
    "    print(\">>> 피트스톱 데이터 오버샘플링 (ADASYN)...\")\n",
    "    adasyn = ADASYN(sampling_strategy=0.3, random_state=42)\n",
    "    # X_train이 아닌 X_train_transformed를 사용해야 합니다.\n",
    "    X_train_pit_res, y_pitstop_train_res = adasyn.fit_resample(X_train_transformed, y_pitstop_train)\n",
    "    print(\">>> 오버샘플링 완료.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Optuna 최적화 실행\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=30, n_jobs=-1)\n",
    "\n",
    "    # 최적 파라미터 출력\n",
    "    print(\"Best parameters:\", study.best_params)\n",
    "    print(\"Best score:\", study.best_value)\n",
    "\n",
    "    # 최적 모델 학습 및 평가 (예시)\n",
    "    best_params = study.best_params\n",
    "\n",
    "\n",
    "    # --- 1. 다중 출력 회귀 모델 (LapTime, TyreWear 예측) ---\n",
    "    multi_output_params = best_params.copy()\n",
    "    # 회귀 모델에 불필요한 scale_pos_weight 파라미터 제거\n",
    "    multi_output_params.pop('scale_pos_weight', None) \n",
    "    # 회귀 모델의 objective 명시\n",
    "    multi_output_params['objective'] = 'reg:squarederror'\n",
    "\n",
    "    multi_output_model = xgb.XGBRegressor(**multi_output_params)\n",
    "    # X_train_transformed와 y_multi_train[:, [0, 2]]로 학습\n",
    "    multi_output_model.fit(X_train_transformed, y_multi_train[:, [0, 2]])\n",
    "    print(\"Final Multi-Output Regressor trained with best parameters.\")\n",
    "\n",
    "\n",
    "    # --- 2. 피트스톱 분류 모델 ---\n",
    "    pitstop_params = best_params.copy()\n",
    "    # 분류 모델의 objective 명시 (기존 값을 덮어씀)\n",
    "    pitstop_params['objective'] = 'binary:logistic'\n",
    "\n",
    "    xgb_pitstop = xgb.XGBClassifier(**pitstop_params)\n",
    "    # X_train_pit_res, y_pitstop_train_res (오버샘플링된 데이터)로 학습\n",
    "    xgb_pitstop.fit(X_train_pit_res, y_pitstop_train_res)\n",
    "    print(\"Final PitStop Classifier trained with best parameters.\")\n",
    "\n",
    "\n",
    "    # PHASE 3: Dry Strategy 파라미터 계산\n",
    "    print(\"\\nPHASE 3: Dry Strategy 파라미터 계산 시작\")\n",
    "    # ML 모델 관련 파라미터 (Grouped 데이터 사용)\n",
    "    print(\">>> Grouped 데이터로 ML 기반 파라미터 계산...\")\n",
    "    X_dry_test_grouped = preprocessor.transform(dry_laps_data_grouped)\n",
    "    y_dry_pitstop_test_grouped = (dry_laps_data_grouped['PitInTime'].notna()).astype(int)\n",
    "    y_dry_pitstop_proba_grouped = xgb_pitstop.predict_proba(X_dry_test_grouped)[:, 1]\n",
    "    dry_pit_proba_threshold = calculate_pit_proba_threshold(y_dry_pitstop_test_grouped, y_dry_pitstop_proba_grouped)\n",
    "    dry_tyrelife_threshold = calculate_tyre_wear_threshold(dry_laps_data_grouped)\n",
    "\n",
    "    # 컴파운드 성능 파라미터 (Grouped 데이터 사용)\n",
    "    dry_compound_performance = calculate_all_compound_performance(dry_laps_data_grouped)\n",
    "\n",
    "    # 트랙 고유 파라미터 (Single 데이터 사용)\n",
    "    print(\"\\n>>> Single 데이터로 트랙 고유 파라미터 계산...\")\n",
    "    dry_compound_choice_thresholds = find_compound_choice_thresholds(dry_laps_data_single, track_name)\n",
    "    dry_pit_stop_time = calculate_pit_stop_time(dry_laps_data_single, track_name)\n",
    "    print(\"PHASE 3: 완료\")\n",
    "\n",
    "\n",
    "    # PHASE 4: Wet Strategy 파라미터 계산\n",
    "    print(\"\\nPHASE 4: Wet Strategy 파라미터 계산 시작\")\n",
    "    wet_compound_performance = {}\n",
    "    wet_pit_stop_time = 24.5  # 기본값 또는 계산값\n",
    "    if has_wet_data:\n",
    "        # Wet 데이터는 양이 적으므로 항상 Grouped 데이터를 사용\n",
    "        wet_compound_performance = calculate_all_compound_performance(wet_laps_data_grouped)\n",
    "        wet_pit_stop_time = calculate_pit_stop_time(wet_laps_data_grouped, track_name)\n",
    "        print(\"PHASE 4: 완료\")\n",
    "    else:\n",
    "        print(\"Wet 데이터가 없어 PHASE 4를 건너뜁니다.\")\n",
    "\n",
    "\n",
    "\n",
    "    # ==============================================================================\n",
    "    # PHASE 5: 결과 통합 및 최종 JSON 파일 저장\n",
    "    # ==============================================================================\n",
    "    print(\"\\nPHASE 5: 최종 JSON 파일 생성 시작\")\n",
    "\n",
    "    final_json_data = {\n",
    "        \"metadata\": {\n",
    "            \"track\": track_name,\n",
    "            \"version\": \"2.0\",\n",
    "            \"description\": f\"{track_name} GP F1 strategy simulation parameters with Dry/Wet separation.\",\n",
    "            \"created_at\": datetime.now().isoformat()\n",
    "        },\n",
    "        \"dry_strategy_params\": {\n",
    "            \"description\": \"Parameters for when Rainfall is 0. Uses ML-based predictions.\",\n",
    "            \"ml_hyper_parameters\": best_params, # Optuna에서 찾은 최적 파라미터\n",
    "            \"pit_proba_threshold\": dry_pit_proba_threshold,\n",
    "            \"TyreLife_threshold\": dry_tyrelife_threshold,\n",
    "            # \"compound_choice_thresholds\": dry_pit_stop_data_result,\n",
    "            \"pit_stop_time\": dry_pit_stop_time,\n",
    "            \"compound_performance\": {\n",
    "                # dry_compound_performance에서 SOFT, MEDIUM, HARD 키가 있는 항목만 필터링\n",
    "                compound: dry_compound_performance[compound]\n",
    "                for compound in ['SOFT', 'MEDIUM', 'HARD']\n",
    "                if compound in dry_compound_performance\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if has_wet_data:\n",
    "        final_json_data[\"wet_strategy_params\"] = {\n",
    "            \"description\": \"Parameters for when Rainfall is 1. Uses rule-based logic.\",\n",
    "            \"strategy_rule\": \"When rainfall begins, recommend immediate pit for INTERMEDIATE tires.\",\n",
    "            \"pit_stop_time\": wet_pit_stop_time,\n",
    "            \"compound_performance\": {\n",
    "                # wet_compound_performance에서 INTERMEDIATE, WET 키가 있는 항목만 필터링\n",
    "                compound: wet_compound_performance[compound]\n",
    "                for compound in ['INTERMEDIATE', 'WET']\n",
    "                if compound in wet_compound_performance\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # --- 이 부분이 핵심적인 수정 사항입니다 ---\n",
    "    print(\">>> NumPy 타입을 Python 기본 타입으로 변환 중...\")\n",
    "    final_json_data_serializable = convert_numpy_types(final_json_data)\n",
    "    print(\">>> 변환 완료.\")\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # 최종 JSON 파일 저장\n",
    "    output_filename = f\"/home/azureuser/cloudfiles/code/Users/project/src/tyre_strategy_module/json_result/complete/{track_name}_complete_strategy_params_v2.json\"\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        # 변환된 객체를 json.dump에 전달합니다.\n",
    "        json.dump(final_json_data_serializable, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n✅ 최종 파라미터 파일이 '{output_filename}'으로 성공적으로 저장되었습니다.\")\n",
    "    print(\"PHASE 5: 완료\")\n",
    "\n",
    "\n",
    "\n",
    "    # 해당 트랙의 파라미터 파일 로드\n",
    "    params_filename = f\"/home/azureuser/cloudfiles/code/Users/project/src/tyre_strategy_module/json_result/complete/{track_name}_complete_strategy_params_v2.json\"\n",
    "    try:\n",
    "        with open(params_filename, 'r', encoding='utf-8') as f:\n",
    "            params_data = json.load(f)\n",
    "        print(f\"✅ '{params_filename}' 파라미터 로딩 완료.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 에러: 파라미터 파일 '{params_filename}'을 찾을 수 없습니다.\")\n",
    "        exit()\n",
    "\n",
    "    best_params = params_data[\"dry_strategy_params\"][\"ml_hyper_parameters\"]\n",
    "\n",
    "    # 시뮬레이션용 랩 데이터 준비 (이 부분은 모델 예측이 끝난 후 실행되어야 함)\n",
    "    # (X_test, multi_output_model, xgb_pitstop 등이 이미 메모리에 있다고 가정)\n",
    "    print(\">>> 시뮬레이션용 랩 데이터 준비 중...\")\n",
    "    y_pred_multi = multi_output_model.predict(X_test_transformed)\n",
    "    y_pred_laptime = y_pred_multi[:, 0]\n",
    "    y_pred_tyrewear = y_pred_multi[:, 1]\n",
    "    y_pred_pitstop_proba = xgb_pitstop.predict_proba(X_test_transformed)[:, 1]\n",
    "    # ... (이전과 동일한 lap_data_df 생성 로직) ...\n",
    "    # 시뮬레이션 입력 데이터프레임 생성\n",
    "    lap_numbers = X_test['LapNumber'].values\n",
    "    rainfall = X_test['Rainfall'].values if 'Rainfall' in X_test.columns else np.zeros(len(X_test))\n",
    "    track_temp = X_test['TrackTemp'].values if 'TrackTemp' in X_test.columns else np.full(len(X_test), 30.0)\n",
    "    lap_time_delta = X_test['LapTime_Delta'].values if 'LapTime_Delta' in X_test.columns else np.zeros(len(X_test))\n",
    "\n",
    "    lap_data_df = pd.DataFrame({\n",
    "        'lap': lap_numbers,\n",
    "        'laptime': y_pred_laptime,\n",
    "        'tyre_wear': y_pred_tyrewear,\n",
    "        'pit_proba': y_pred_pitstop_proba,\n",
    "        'lap_delta': lap_time_delta,\n",
    "        'rainfall': rainfall,\n",
    "        'track_temp': track_temp\n",
    "    })\n",
    "    lap_data_df = lap_data_df.groupby('lap').mean().reset_index().sort_values('lap')\n",
    "    print(f\"✅ 랩 데이터 준비 완료. (총 {len(lap_data_df)} 랩)\")\n",
    "\n",
    "    \n",
    "    for initial_compound in compound :\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # [ STEP 4: 유전 알고리즘을 이용한 최적 전략 탐색 ]\n",
    "        # ------------------------------------------------------------------------------\n",
    "        print(\"\\n>>> STEP 4: 유전 알고리즘으로 최적 전략 탐색 시작...\")\n",
    "\n",
    "        # ==============================================================================\n",
    "        #           <<<< 유전 알고리즘 기반 F1 전략 탐색 엔진 (수정 완료) >>>>\n",
    "        # ==============================================================================\n",
    "\n",
    "        # --- 1. 유전 알고리즘 기본 설정 (RuntimeWarning 방지 코드 추가) ---\n",
    "        # 이전에 생성된 클래스가 있다면 삭제하여 경고 메시지 방지\n",
    "        if hasattr(creator, \"FitnessMin\"):\n",
    "            del creator.FitnessMin\n",
    "        if hasattr(creator, \"Individual\"):\n",
    "            del creator.Individual\n",
    "\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "        toolbox = base.Toolbox()\n",
    "\n",
    "\n",
    "        # --- 2. 유전자(Gene) 및 염색체(Chromosome) 정의 (수정된 버전) ---\n",
    "\n",
    "        COMPOUNDS = ['SOFT', 'MEDIUM', 'HARD']\n",
    "\n",
    "        # toolbox에 위 함수를 'individual'이라는 이름으로 등록 (이 부분은 동일)\n",
    "        toolbox.register(\"individual\", create_random_strategy, race_laps=race_laps)\n",
    "        # toolbox에 'population'을 individual의 리스트로 정의 (이 부분은 동일)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "        # --- 4. 교배, 돌연변이, 선택 연산자 정의 (규칙 준수 버전) ---\n",
    "        # (custom_mutate, custom_mate 등 이전과 동일)\n",
    "        toolbox.register(\"evaluate\", evaluate_hybrid_strategy) # <--- 업그레이드된 함수로 교체!\n",
    "        toolbox.register(\"mate\", custom_mate)\n",
    "        toolbox.register(\"mutate\", custom_mutate, low=[10,0,0,0], up=[race_laps-10, 2, race_laps-10, 2], indpb=0.2)\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "        # --- 5. 유전 알고리즘 실행 (이전과 동일) ---\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"GENETIC ALGORITHM: SEARCHING FOR OPTIMAL STRATEGY (v2, Rule-Compliant)...\")\n",
    "        print(\"=\"*60)\n",
    "        population = toolbox.population(n=50)\n",
    "        NGEN = 40\n",
    "        CXPB, MUTPB = 0.5, 0.2\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean); stats.register(\"min\", np.min); stats.register(\"max\", np.max)\n",
    "        result_pop, logbook = algorithms.eaSimple(population, toolbox, CXPB, MUTPB, NGEN, stats=stats, verbose=True)\n",
    "\n",
    "        # --- 6. 최종 결과 출력 (이전과 동일) ---\n",
    "        best_individual = tools.selBest(result_pop, k=1)[0]\n",
    "        best_fitness = best_individual.fitness.values[0]\n",
    "        pit1_lap, pit1_tyre_idx, pit2_lap, pit2_tyre_idx = best_individual\n",
    "\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # [ STEP 5: 최종 결과 출력 ]\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # (GA 실행 후 best_individual을 해석하여 결과를 출력하는 코드)\n",
    "        # ...\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"OPTIMAL STRATEGY (FOUND BY GENETIC ALGORITHM)\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        pit_stops = []\n",
    "\n",
    "        if pit1_lap > 0:\n",
    "            pit_stops.append({'lap': int(pit1_lap), 'tyre': COMPOUNDS[pit1_tyre_idx]})\n",
    "        if pit2_lap > 0:\n",
    "            pit_stops.append({'lap': int(pit2_lap), 'tyre': COMPOUNDS[pit2_tyre_idx]})\n",
    "\n",
    "        # 만약을 위해 피트스톱 랩 순서대로 정렬\n",
    "        pit_stops = sorted(pit_stops, key=lambda x: x['lap'])\n",
    "\n",
    "        # --- 2. 최종 결과 요약 출력 ---\n",
    "\n",
    "\n",
    "        # 한 줄 요약 문자열 생성\n",
    "        strategy_summary = f\"Start with {initial_compound} -> \"\n",
    "        if not pit_stops:\n",
    "            strategy_summary = f\"0-Stop: Run entire race on {initial_compound}\"\n",
    "        else:\n",
    "            for pit in pit_stops:\n",
    "                strategy_summary += f\"Lap {pit['lap']} PIT to {pit['tyre']} -> \"\n",
    "        strategy_summary += \"Finish\"\n",
    "\n",
    "        print(f\"🏆 Best Strategy Found: {strategy_summary}\")\n",
    "        print(f\"⏱️ Estimated Race Time: {best_fitness/60:.2f} minutes\")\n",
    "        print(f\"🔧 Total Pit Stops: {len(pit_stops)}\")\n",
    "\n",
    "        # --- 3. 스틴트별 상세 전략 출력 ---\n",
    "        if not pit_stops:\n",
    "            print(f\"\\n📅 STINT DETAILS:\")\n",
    "            print(f\" └─ Stint 1: Laps 1-{race_laps} ({race_laps} Laps) on {initial_compound}\")\n",
    "        else:\n",
    "            print(f\"\\n📅 PIT STOP SCHEDULE:\")\n",
    "            current_compound = initial_compound\n",
    "            stint_start_lap = 1\n",
    "            \n",
    "            for i, pit in enumerate(pit_stops):\n",
    "                end_lap = pit['lap']\n",
    "                stint_length = end_lap - stint_start_lap + 1\n",
    "                print(f\" ├─ Stint {i+1}: Laps {stint_start_lap}-{end_lap} ({stint_length} Laps) on {current_compound}\")\n",
    "                \n",
    "                # 다음 스틴트를 위해 변수 업데이트\n",
    "                current_compound = pit['tyre']\n",
    "                stint_start_lap = end_lap + 1\n",
    "            \n",
    "            # 마지막 스틴트 출력\n",
    "            final_stint_length = race_laps - stint_start_lap + 1\n",
    "            if final_stint_length > 0:\n",
    "                print(f\" └─ Stint {len(pit_stops)+1}: Laps {stint_start_lap}-{race_laps} ({final_stint_length} Laps) on {current_compound}\")\n",
    "\n",
    "\n",
    "        # --- 3. ⭐️ 최종 결과를 JSON 형식으로 생성 및 출력 (API 출력용) ⭐️ ---\n",
    "        final_result_json = {}\n",
    "        final_result_json['track_name'] = track_name\n",
    "        final_result_json['total_laps'] = race_laps\n",
    "        final_result_json['estimated_race_time_seconds'] = best_fitness\n",
    "        final_result_json['estimated_race_time_minutes'] = round(best_fitness / 60, 2)\n",
    "        final_result_json['total_pit_stops'] = len(pit_stops)\n",
    "        final_result_json['strategy_summary'] = strategy_summary\n",
    "\n",
    "        # 스틴트 정보를 JSON 구조에 맞게 재구성\n",
    "        stints_list = []\n",
    "        current_compound = initial_compound\n",
    "        stint_start_lap = 1\n",
    "\n",
    "        if not pit_stops:\n",
    "            stints_list.append({\n",
    "                \"stint_number\": 1, \"compound\": current_compound, \"start_lap\": stint_start_lap,\n",
    "                \"end_lap\": race_laps, \"stint_length\": race_laps\n",
    "            })\n",
    "        else:\n",
    "            for i, pit in enumerate(pit_stops):\n",
    "                end_lap = pit['lap']\n",
    "                stint_length = end_lap - stint_start_lap + 1\n",
    "                stints_list.append({\n",
    "                    \"stint_number\": i + 1, \"compound\": current_compound, \"start_lap\": stint_start_lap,\n",
    "                    \"end_lap\": end_lap, \"stint_length\": stint_length\n",
    "                })\n",
    "                current_compound = pit['tyre']\n",
    "                stint_start_lap = end_lap + 1\n",
    "            \n",
    "            final_stint_length = race_laps - stint_start_lap + 1\n",
    "            if final_stint_length > 0:\n",
    "                stints_list.append({\n",
    "                    \"stint_number\": len(pit_stops) + 1, \"compound\": current_compound, \"start_lap\": stint_start_lap,\n",
    "                    \"end_lap\": race_laps, \"stint_length\": final_stint_length\n",
    "                })\n",
    "\n",
    "        final_result_json['stints'] = stints_list\n",
    "\n",
    "        # JSON 형식으로 콘솔에 예쁘게 출력\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FINAL STRATEGY AS JSON (FOR API OUTPUT)\")\n",
    "        print(\"=\"*60)\n",
    "        # NumPy 타입을 안전하게 변환 후 출력\n",
    "        final_result_json_serializable = convert_numpy_types(final_result_json)\n",
    "        print(json.dumps(final_result_json_serializable, indent=2, ensure_ascii=False))\n",
    "\n",
    "        # 최종 JSON 파일 저장\n",
    "        output_filename = f\"/home/azureuser/cloudfiles/code/Users/project/src/tyre_strategy_module/json_result/result/{track_name}_{initial_compound}_strategy_result.json\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            # 변환된 객체를 json.dump에 전달합니다.\n",
    "            json.dump(final_result_json_serializable, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
