{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8b21ab",
      "metadata": {
        "gather": {
          "logged": 1753626946554
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from Users.project.src.deep_learning_pipeline.context import Context\n",
        "from Users.project.src.deep_learning_pipeline.loss_func import MSELossFuncCreator\n",
        "from Users.project.src.deep_learning_pipeline.optimizer import AdamOptimizerCreator\n",
        "from Users.project.src.base.logger import ConsoleLogger, FileLogger\n",
        "from Users.project.src.deep_learning_pipeline.learning_input import LearningInput\n",
        "from Users.project.src.deep_learning_pipeline.model_creator import ModelManager\n",
        "from Users.project.src.deep_learning_pipeline.scaler_manager import ScalerManager\n",
        "from Users.project.src.predict_lab_time_module.all_track_model import SimpleModel_128_Hidden_1_Creator, SimpleModel_128_Hidden_2_Creator\n",
        "from Users.project.src.predict_lab_time_module.all_track_model import SimpleModel_64_Hidden_2_Creator, SimpleModel_64_Hidden_1_Creator\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torch import nn, optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "data_save_dir = os.path.join(\"Users\", \"project\", \"data\", \"lap_time_predict\")\n",
        "features_path = os.path.join(data_save_dir, \"features.csv\")\n",
        "features = pd.read_csv(features_path)\n",
        "labels_path = os.path.join(data_save_dir, \"labels.csv\")\n",
        "labels = pd.read_csv(labels_path)\n",
        "\n",
        "model_path = os.path.join(\"Users\", \"project\", \"model\", \"lap_time_predict_test_4\")\n",
        "log_path = os.path.join(\"Users\", \"project\", \"log\", \"lap_time_predict_test_4\")\n",
        "\n",
        "model_creators = [SimpleModel_128_Hidden_1_Creator(), SimpleModel_128_Hidden_2_Creator()\n",
        "                  , SimpleModel_64_Hidden_1_Creator(), SimpleModel_64_Hidden_2_Creator()]\n",
        "\n",
        "optimizer_creator = AdamOptimizerCreator()\n",
        "loss_func_creator = MSELossFuncCreator()\n",
        "\n",
        "learning_input = LearningInput(features, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "16882850",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/200], Train Loss: 0.1809, Validation Loss: 0.1117\n",
            "Epoch [20/200], Train Loss: 0.1199, Validation Loss: 0.0260\n",
            "Epoch [30/200], Train Loss: 0.0739, Validation Loss: 0.0067\n",
            "Epoch [40/200], Train Loss: 0.0541, Validation Loss: 0.3633\n",
            "Epoch [50/200], Train Loss: 0.0371, Validation Loss: 0.0288\n",
            "Epoch [60/200], Train Loss: 0.0794, Validation Loss: 0.0041\n",
            "Epoch [70/200], Train Loss: 0.0375, Validation Loss: 0.0369\n",
            "Epoch [80/200], Train Loss: 0.0357, Validation Loss: 0.0105\n",
            "Epoch [90/200], Train Loss: 0.0298, Validation Loss: 0.0016\n",
            "Epoch [100/200], Train Loss: 0.0227, Validation Loss: 0.0032\n",
            "Epoch [110/200], Train Loss: 0.0229, Validation Loss: 0.0122\n",
            "Epoch [120/200], Train Loss: 0.0184, Validation Loss: 0.0116\n",
            "Epoch [130/200], Train Loss: 0.0250, Validation Loss: 0.0030\n",
            "Epoch [140/200], Train Loss: 0.0152, Validation Loss: 0.0013\n",
            "Epoch [150/200], Train Loss: 0.0159, Validation Loss: 0.0125\n",
            "Epoch [160/200], Train Loss: 0.0191, Validation Loss: 0.0004\n",
            "Epoch [170/200], Train Loss: 0.0166, Validation Loss: 0.1259\n",
            "\n",
            "Early stopping triggered at epoch 173 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 123 with Validation Loss 0.0003 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2627, Validation Loss: 0.2093\n",
            "Epoch [20/200], Train Loss: 0.1536, Validation Loss: 0.0436\n",
            "Epoch [30/200], Train Loss: 0.0791, Validation Loss: 0.0488\n",
            "Epoch [40/200], Train Loss: 0.0745, Validation Loss: 0.0166\n",
            "Epoch [50/200], Train Loss: 0.0519, Validation Loss: 0.0317\n",
            "Epoch [60/200], Train Loss: 0.0401, Validation Loss: 0.0073\n",
            "Epoch [70/200], Train Loss: 0.0252, Validation Loss: 0.0137\n",
            "Epoch [80/200], Train Loss: 0.0295, Validation Loss: 0.0711\n",
            "Epoch [90/200], Train Loss: 0.0296, Validation Loss: 0.0607\n",
            "Epoch [100/200], Train Loss: 0.0202, Validation Loss: 0.0034\n",
            "Epoch [110/200], Train Loss: 0.0171, Validation Loss: 0.0034\n",
            "Epoch [120/200], Train Loss: 0.0118, Validation Loss: 0.0012\n",
            "Epoch [130/200], Train Loss: 0.0152, Validation Loss: 0.0052\n",
            "Epoch [140/200], Train Loss: 0.0134, Validation Loss: 0.0083\n",
            "Epoch [150/200], Train Loss: 0.0114, Validation Loss: 0.0014\n",
            "Epoch [160/200], Train Loss: 0.0103, Validation Loss: 0.0237\n",
            "Epoch [170/200], Train Loss: 0.0103, Validation Loss: 0.0045\n",
            "Epoch [180/200], Train Loss: 0.0089, Validation Loss: 0.0567\n",
            "Epoch [190/200], Train Loss: 0.0087, Validation Loss: 0.0137\n",
            "Epoch [200/200], Train Loss: 0.0070, Validation Loss: 0.0340\n",
            "\n",
            "Training finished. Best model from Epoch 163 with Validation Loss 0.0000 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1000, Validation Loss: 0.1084\n",
            "Epoch [20/200], Train Loss: 0.0713, Validation Loss: 0.0140\n",
            "Epoch [30/200], Train Loss: 0.0484, Validation Loss: 0.0452\n",
            "Epoch [40/200], Train Loss: 0.0335, Validation Loss: 0.0077\n",
            "Epoch [50/200], Train Loss: 0.0317, Validation Loss: 0.0012\n",
            "Epoch [60/200], Train Loss: 0.0234, Validation Loss: 0.0444\n",
            "Epoch [70/200], Train Loss: 0.0334, Validation Loss: 0.0212\n",
            "Epoch [80/200], Train Loss: 0.0346, Validation Loss: 0.0109\n",
            "Epoch [90/200], Train Loss: 0.0184, Validation Loss: 0.0200\n",
            "Epoch [100/200], Train Loss: 0.0187, Validation Loss: 0.0088\n",
            "Epoch [110/200], Train Loss: 0.0138, Validation Loss: 0.0038\n",
            "\n",
            "Early stopping triggered at epoch 117 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 67 with Validation Loss 0.0008 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1617, Validation Loss: 0.1666\n",
            "Epoch [20/200], Train Loss: 0.1293, Validation Loss: 0.0232\n",
            "Epoch [30/200], Train Loss: 0.0744, Validation Loss: 0.0533\n",
            "Epoch [40/200], Train Loss: 0.0490, Validation Loss: 0.0029\n",
            "Epoch [50/200], Train Loss: 0.0381, Validation Loss: 0.0172\n",
            "Epoch [60/200], Train Loss: 0.0267, Validation Loss: 0.0300\n",
            "Epoch [70/200], Train Loss: 0.0421, Validation Loss: 0.0284\n",
            "Epoch [80/200], Train Loss: 0.0262, Validation Loss: 0.0025\n",
            "Epoch [90/200], Train Loss: 0.0263, Validation Loss: 0.0012\n",
            "Epoch [100/200], Train Loss: 0.0175, Validation Loss: 0.0062\n",
            "Epoch [110/200], Train Loss: 0.0273, Validation Loss: 0.0064\n",
            "Epoch [120/200], Train Loss: 0.0205, Validation Loss: 0.0078\n",
            "Epoch [130/200], Train Loss: 0.0168, Validation Loss: 0.0016\n",
            "Epoch [140/200], Train Loss: 0.0153, Validation Loss: 0.0189\n",
            "Epoch [150/200], Train Loss: 0.0161, Validation Loss: 0.0002\n",
            "Epoch [160/200], Train Loss: 0.0104, Validation Loss: 0.0003\n",
            "Epoch [170/200], Train Loss: 0.0100, Validation Loss: 0.1507\n",
            "Epoch [180/200], Train Loss: 0.0143, Validation Loss: 0.0022\n",
            "Epoch [190/200], Train Loss: 0.0115, Validation Loss: 0.0080\n",
            "Epoch [200/200], Train Loss: 0.0103, Validation Loss: 0.0047\n",
            "\n",
            "Training finished. Best model from Epoch 173 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1920, Validation Loss: 0.0395\n",
            "Epoch [20/200], Train Loss: 0.1450, Validation Loss: 0.1190\n",
            "Epoch [30/200], Train Loss: 0.0670, Validation Loss: 0.2265\n",
            "Epoch [40/200], Train Loss: 0.0567, Validation Loss: 0.0787\n",
            "Epoch [50/200], Train Loss: 0.0435, Validation Loss: 0.0633\n",
            "Epoch [60/200], Train Loss: 0.0475, Validation Loss: 0.0018\n",
            "Epoch [70/200], Train Loss: 0.0341, Validation Loss: 0.0033\n",
            "Epoch [80/200], Train Loss: 0.0299, Validation Loss: 0.0117\n",
            "Epoch [90/200], Train Loss: 0.0290, Validation Loss: 0.0533\n",
            "Epoch [100/200], Train Loss: 0.0254, Validation Loss: 0.0356\n",
            "Epoch [110/200], Train Loss: 0.0182, Validation Loss: 0.0041\n",
            "Epoch [120/200], Train Loss: 0.0183, Validation Loss: 0.0038\n",
            "Epoch [130/200], Train Loss: 0.0206, Validation Loss: 0.0032\n",
            "Epoch [140/200], Train Loss: 0.0099, Validation Loss: 0.0166\n",
            "Epoch [150/200], Train Loss: 0.0151, Validation Loss: 0.0170\n",
            "Epoch [160/200], Train Loss: 0.0138, Validation Loss: 0.0705\n",
            "Epoch [170/200], Train Loss: 0.0122, Validation Loss: 0.0003\n",
            "Epoch [180/200], Train Loss: 0.0106, Validation Loss: 0.0030\n",
            "Epoch [190/200], Train Loss: 0.0098, Validation Loss: 0.0168\n",
            "Epoch [200/200], Train Loss: 0.0103, Validation Loss: 0.0412\n",
            "\n",
            "Training finished. Best model from Epoch 169 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2169, Validation Loss: 0.0423\n",
            "Epoch [20/200], Train Loss: 0.1288, Validation Loss: 0.2233\n",
            "Epoch [30/200], Train Loss: 0.0772, Validation Loss: 0.0188\n",
            "Epoch [40/200], Train Loss: 0.0629, Validation Loss: 0.3246\n",
            "Epoch [50/200], Train Loss: 0.0450, Validation Loss: 0.0092\n",
            "Epoch [60/200], Train Loss: 0.0525, Validation Loss: 0.0127\n",
            "Epoch [70/200], Train Loss: 0.0353, Validation Loss: 0.0159\n",
            "Epoch [80/200], Train Loss: 0.0276, Validation Loss: 0.0011\n",
            "Epoch [90/200], Train Loss: 0.0347, Validation Loss: 0.1156\n",
            "Epoch [100/200], Train Loss: 0.0310, Validation Loss: 0.0018\n",
            "Epoch [110/200], Train Loss: 0.0213, Validation Loss: 0.0891\n",
            "Epoch [120/200], Train Loss: 0.0192, Validation Loss: 0.0051\n",
            "Epoch [130/200], Train Loss: 0.0194, Validation Loss: 0.0006\n",
            "Epoch [140/200], Train Loss: 0.0145, Validation Loss: 0.0006\n",
            "Epoch [150/200], Train Loss: 0.0194, Validation Loss: 0.0110\n",
            "Epoch [160/200], Train Loss: 0.0167, Validation Loss: 0.0122\n",
            "Epoch [170/200], Train Loss: 0.0152, Validation Loss: 0.0112\n",
            "Epoch [180/200], Train Loss: 0.0165, Validation Loss: 0.0005\n",
            "Epoch [190/200], Train Loss: 0.0134, Validation Loss: 0.0057\n",
            "Epoch [200/200], Train Loss: 0.0136, Validation Loss: 0.0030\n",
            "\n",
            "Training finished. Best model from Epoch 165 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1306, Validation Loss: 0.0562\n",
            "Epoch [20/200], Train Loss: 0.0656, Validation Loss: 0.0105\n",
            "Epoch [30/200], Train Loss: 0.0486, Validation Loss: 0.0147\n",
            "Epoch [40/200], Train Loss: 0.0450, Validation Loss: 0.0037\n",
            "Epoch [50/200], Train Loss: 0.0535, Validation Loss: 0.0007\n",
            "Epoch [60/200], Train Loss: 0.0313, Validation Loss: 0.0056\n",
            "Epoch [70/200], Train Loss: 0.0273, Validation Loss: 0.0005\n",
            "Epoch [80/200], Train Loss: 0.0274, Validation Loss: 0.0027\n",
            "Epoch [90/200], Train Loss: 0.0165, Validation Loss: 0.0364\n",
            "Epoch [100/200], Train Loss: 0.0175, Validation Loss: 0.0142\n",
            "Epoch [110/200], Train Loss: 0.0178, Validation Loss: 0.0038\n",
            "Epoch [120/200], Train Loss: 0.0148, Validation Loss: 0.0012\n",
            "Epoch [130/200], Train Loss: 0.0141, Validation Loss: 0.0043\n",
            "Epoch [140/200], Train Loss: 0.0214, Validation Loss: 0.0011\n",
            "Epoch [150/200], Train Loss: 0.0203, Validation Loss: 0.0206\n",
            "Epoch [160/200], Train Loss: 0.0131, Validation Loss: 0.0003\n",
            "Epoch [170/200], Train Loss: 0.0096, Validation Loss: 0.0067\n",
            "Epoch [180/200], Train Loss: 0.0119, Validation Loss: 0.0196\n",
            "Epoch [190/200], Train Loss: 0.0091, Validation Loss: 0.0013\n",
            "Epoch [200/200], Train Loss: 0.0110, Validation Loss: 0.0020\n",
            "\n",
            "Training finished. Best model from Epoch 189 with Validation Loss 0.0002 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2159, Validation Loss: 0.0392\n",
            "Epoch [20/200], Train Loss: 0.1100, Validation Loss: 0.0287\n",
            "Epoch [30/200], Train Loss: 0.0536, Validation Loss: 0.0829\n",
            "Epoch [40/200], Train Loss: 0.0495, Validation Loss: 0.0534\n",
            "Epoch [50/200], Train Loss: 0.0471, Validation Loss: 0.0327\n",
            "Epoch [60/200], Train Loss: 0.0332, Validation Loss: 0.0781\n",
            "Epoch [70/200], Train Loss: 0.0352, Validation Loss: 0.0020\n",
            "Epoch [80/200], Train Loss: 0.0259, Validation Loss: 0.0361\n",
            "Epoch [90/200], Train Loss: 0.0313, Validation Loss: 0.0278\n",
            "Epoch [100/200], Train Loss: 0.0169, Validation Loss: 0.0014\n",
            "Epoch [110/200], Train Loss: 0.0239, Validation Loss: 0.0140\n",
            "Epoch [120/200], Train Loss: 0.0150, Validation Loss: 0.0177\n",
            "Epoch [130/200], Train Loss: 0.0154, Validation Loss: 0.0001\n",
            "Epoch [140/200], Train Loss: 0.0123, Validation Loss: 0.0069\n",
            "Epoch [150/200], Train Loss: 0.0104, Validation Loss: 0.0038\n",
            "Epoch [160/200], Train Loss: 0.0095, Validation Loss: 0.0022\n",
            "Epoch [170/200], Train Loss: 0.0108, Validation Loss: 0.0173\n",
            "Epoch [180/200], Train Loss: 0.0116, Validation Loss: 0.0915\n",
            "Epoch [190/200], Train Loss: 0.0087, Validation Loss: 0.0125\n",
            "Epoch [200/200], Train Loss: 0.0094, Validation Loss: 0.0442\n",
            "\n",
            "Training finished. Best model from Epoch 173 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2609, Validation Loss: 0.0936\n",
            "Epoch [20/200], Train Loss: 0.1046, Validation Loss: 0.0211\n",
            "Epoch [30/200], Train Loss: 0.1160, Validation Loss: 0.0187\n",
            "Epoch [40/200], Train Loss: 0.0765, Validation Loss: 0.0054\n",
            "Epoch [50/200], Train Loss: 0.0483, Validation Loss: 0.0074\n",
            "Epoch [60/200], Train Loss: 0.0309, Validation Loss: 0.0039\n",
            "Epoch [70/200], Train Loss: 0.0400, Validation Loss: 0.0005\n",
            "Epoch [80/200], Train Loss: 0.0267, Validation Loss: 0.1346\n",
            "Epoch [90/200], Train Loss: 0.0295, Validation Loss: 0.0048\n",
            "Epoch [100/200], Train Loss: 0.0174, Validation Loss: 0.0026\n",
            "Epoch [110/200], Train Loss: 0.0221, Validation Loss: 0.0069\n",
            "Epoch [120/200], Train Loss: 0.0330, Validation Loss: 0.1206\n",
            "Epoch [130/200], Train Loss: 0.0240, Validation Loss: 0.0004\n",
            "Epoch [140/200], Train Loss: 0.0177, Validation Loss: 0.0245\n",
            "\n",
            "Early stopping triggered at epoch 147 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 97 with Validation Loss 0.0003 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2132, Validation Loss: 0.0346\n",
            "Epoch [20/200], Train Loss: 0.1184, Validation Loss: 0.2033\n",
            "Epoch [30/200], Train Loss: 0.0780, Validation Loss: 0.0202\n",
            "Epoch [40/200], Train Loss: 0.0744, Validation Loss: 0.0635\n",
            "Epoch [50/200], Train Loss: 0.0624, Validation Loss: 0.0184\n",
            "Epoch [60/200], Train Loss: 0.0559, Validation Loss: 0.0039\n",
            "Epoch [70/200], Train Loss: 0.0393, Validation Loss: 0.0099\n",
            "Epoch [80/200], Train Loss: 0.0349, Validation Loss: 0.0127\n",
            "Epoch [90/200], Train Loss: 0.0264, Validation Loss: 0.0529\n",
            "Epoch [100/200], Train Loss: 0.0284, Validation Loss: 0.0006\n",
            "Epoch [110/200], Train Loss: 0.0218, Validation Loss: 0.0824\n",
            "Epoch [120/200], Train Loss: 0.0186, Validation Loss: 0.0273\n",
            "Epoch [130/200], Train Loss: 0.0189, Validation Loss: 0.0235\n",
            "Epoch [140/200], Train Loss: 0.0224, Validation Loss: 0.0019\n",
            "Epoch [150/200], Train Loss: 0.0179, Validation Loss: 0.0397\n",
            "Epoch [160/200], Train Loss: 0.0173, Validation Loss: 0.0049\n",
            "Epoch [170/200], Train Loss: 0.0153, Validation Loss: 0.0031\n",
            "Epoch [180/200], Train Loss: 0.0173, Validation Loss: 0.0005\n",
            "Epoch [190/200], Train Loss: 0.0146, Validation Loss: 0.0019\n",
            "Epoch [200/200], Train Loss: 0.0129, Validation Loss: 0.0036\n",
            "\n",
            "Training finished. Best model from Epoch 186 with Validation Loss 0.0002 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1473, Validation Loss: 0.0713\n",
            "Epoch [20/200], Train Loss: 0.0991, Validation Loss: 0.0752\n",
            "Epoch [30/200], Train Loss: 0.0486, Validation Loss: 0.0881\n",
            "Epoch [40/200], Train Loss: 0.0421, Validation Loss: 0.2584\n",
            "Epoch [50/200], Train Loss: 0.0454, Validation Loss: 0.0955\n",
            "Epoch [60/200], Train Loss: 0.0246, Validation Loss: 0.1340\n",
            "Epoch [70/200], Train Loss: 0.0252, Validation Loss: 0.0208\n",
            "Epoch [80/200], Train Loss: 0.0205, Validation Loss: 0.0002\n",
            "Epoch [90/200], Train Loss: 0.0234, Validation Loss: 0.0076\n",
            "Epoch [100/200], Train Loss: 0.0182, Validation Loss: 0.0674\n",
            "Epoch [110/200], Train Loss: 0.0178, Validation Loss: 0.0024\n",
            "Epoch [120/200], Train Loss: 0.0185, Validation Loss: 0.1264\n",
            "Epoch [130/200], Train Loss: 0.0131, Validation Loss: 0.0006\n",
            "\n",
            "Early stopping triggered at epoch 136 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 86 with Validation Loss 0.0002 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1528, Validation Loss: 0.0228\n",
            "Epoch [20/200], Train Loss: 0.0814, Validation Loss: 0.0111\n",
            "Epoch [30/200], Train Loss: 0.0510, Validation Loss: 0.0091\n",
            "Epoch [40/200], Train Loss: 0.0645, Validation Loss: 0.0525\n",
            "Epoch [50/200], Train Loss: 0.0389, Validation Loss: 0.0394\n",
            "Epoch [60/200], Train Loss: 0.0331, Validation Loss: 0.0185\n",
            "Epoch [70/200], Train Loss: 0.0243, Validation Loss: 0.0241\n",
            "Epoch [80/200], Train Loss: 0.0310, Validation Loss: 0.0236\n",
            "Epoch [90/200], Train Loss: 0.0142, Validation Loss: 0.0022\n",
            "Epoch [100/200], Train Loss: 0.0163, Validation Loss: 0.0093\n",
            "Epoch [110/200], Train Loss: 0.0179, Validation Loss: 0.0577\n",
            "Epoch [120/200], Train Loss: 0.0104, Validation Loss: 0.0170\n",
            "Epoch [130/200], Train Loss: 0.0133, Validation Loss: 0.0058\n",
            "Epoch [140/200], Train Loss: 0.0138, Validation Loss: 0.0002\n",
            "Epoch [150/200], Train Loss: 0.0066, Validation Loss: 0.0098\n",
            "Epoch [160/200], Train Loss: 0.0065, Validation Loss: 0.0009\n",
            "Epoch [170/200], Train Loss: 0.0091, Validation Loss: 0.0012\n",
            "Epoch [180/200], Train Loss: 0.0062, Validation Loss: 0.0008\n",
            "Epoch [190/200], Train Loss: 0.0072, Validation Loss: 0.0140\n",
            "Epoch [200/200], Train Loss: 0.0049, Validation Loss: 0.0003\n",
            "\n",
            "Training finished. Best model from Epoch 158 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2052, Validation Loss: 0.1369\n",
            "Epoch [20/200], Train Loss: 0.1659, Validation Loss: 0.0987\n",
            "Epoch [30/200], Train Loss: 0.0908, Validation Loss: 0.0868\n",
            "Epoch [40/200], Train Loss: 0.0751, Validation Loss: 0.0030\n",
            "Epoch [50/200], Train Loss: 0.0611, Validation Loss: 0.0155\n",
            "Epoch [60/200], Train Loss: 0.0571, Validation Loss: 0.0126\n",
            "Epoch [70/200], Train Loss: 0.0249, Validation Loss: 0.0975\n",
            "Epoch [80/200], Train Loss: 0.0413, Validation Loss: 0.0008\n",
            "Epoch [90/200], Train Loss: 0.0276, Validation Loss: 0.0076\n",
            "Epoch [100/200], Train Loss: 0.0248, Validation Loss: 0.0011\n",
            "Epoch [110/200], Train Loss: 0.0276, Validation Loss: 0.0035\n",
            "Epoch [120/200], Train Loss: 0.0223, Validation Loss: 0.0098\n",
            "Epoch [130/200], Train Loss: 0.0208, Validation Loss: 0.0294\n",
            "Epoch [140/200], Train Loss: 0.0138, Validation Loss: 0.0101\n",
            "Epoch [150/200], Train Loss: 0.0216, Validation Loss: 0.0778\n",
            "Epoch [160/200], Train Loss: 0.0203, Validation Loss: 0.0072\n",
            "Epoch [170/200], Train Loss: 0.0109, Validation Loss: 0.0017\n",
            "Epoch [180/200], Train Loss: 0.0086, Validation Loss: 0.0074\n",
            "Epoch [190/200], Train Loss: 0.0128, Validation Loss: 0.0004\n",
            "Epoch [200/200], Train Loss: 0.0116, Validation Loss: 0.0080\n",
            "\n",
            "Training finished. Best model from Epoch 191 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2042, Validation Loss: 0.1679\n",
            "Epoch [20/200], Train Loss: 0.1298, Validation Loss: 0.0112\n",
            "Epoch [30/200], Train Loss: 0.0779, Validation Loss: 0.0135\n",
            "Epoch [40/200], Train Loss: 0.0754, Validation Loss: 0.0321\n",
            "Epoch [50/200], Train Loss: 0.0833, Validation Loss: 0.0739\n",
            "Epoch [60/200], Train Loss: 0.0529, Validation Loss: 0.0513\n",
            "Epoch [70/200], Train Loss: 0.0410, Validation Loss: 0.0845\n",
            "Epoch [80/200], Train Loss: 0.0417, Validation Loss: 0.0025\n",
            "Epoch [90/200], Train Loss: 0.0264, Validation Loss: 0.0045\n",
            "Epoch [100/200], Train Loss: 0.0258, Validation Loss: 0.0009\n",
            "Epoch [110/200], Train Loss: 0.0356, Validation Loss: 0.0004\n",
            "Epoch [120/200], Train Loss: 0.0210, Validation Loss: 0.0004\n",
            "Epoch [130/200], Train Loss: 0.0233, Validation Loss: 0.0046\n",
            "Epoch [140/200], Train Loss: 0.0229, Validation Loss: 0.0283\n",
            "Epoch [150/200], Train Loss: 0.0240, Validation Loss: 0.1424\n",
            "Epoch [160/200], Train Loss: 0.0182, Validation Loss: 0.0534\n",
            "Epoch [170/200], Train Loss: 0.0178, Validation Loss: 0.0269\n",
            "\n",
            "Early stopping triggered at epoch 175 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 125 with Validation Loss 0.0003 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.0983, Validation Loss: 0.3198\n",
            "Epoch [20/200], Train Loss: 0.0781, Validation Loss: 0.0177\n",
            "Epoch [30/200], Train Loss: 0.0611, Validation Loss: 0.0031\n",
            "Epoch [40/200], Train Loss: 0.0363, Validation Loss: 0.0557\n",
            "Epoch [50/200], Train Loss: 0.0330, Validation Loss: 0.0089\n",
            "Epoch [60/200], Train Loss: 0.0318, Validation Loss: 0.1019\n",
            "Epoch [70/200], Train Loss: 0.0246, Validation Loss: 0.0385\n",
            "Epoch [80/200], Train Loss: 0.0192, Validation Loss: 0.0087\n",
            "Epoch [90/200], Train Loss: 0.0209, Validation Loss: 0.0074\n",
            "Epoch [100/200], Train Loss: 0.0235, Validation Loss: 0.0196\n",
            "Epoch [110/200], Train Loss: 0.0190, Validation Loss: 0.0673\n",
            "\n",
            "Early stopping triggered at epoch 111 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 61 with Validation Loss 0.0007 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2070, Validation Loss: 0.0602\n",
            "Epoch [20/200], Train Loss: 0.0898, Validation Loss: 0.0369\n",
            "Epoch [30/200], Train Loss: 0.0742, Validation Loss: 0.0103\n",
            "Epoch [40/200], Train Loss: 0.0424, Validation Loss: 0.0290\n",
            "Epoch [50/200], Train Loss: 0.0318, Validation Loss: 0.0072\n",
            "Epoch [60/200], Train Loss: 0.0271, Validation Loss: 0.1276\n",
            "Epoch [70/200], Train Loss: 0.0207, Validation Loss: 0.0013\n",
            "Epoch [80/200], Train Loss: 0.0181, Validation Loss: 0.0050\n",
            "Epoch [90/200], Train Loss: 0.0179, Validation Loss: 0.0115\n",
            "Epoch [100/200], Train Loss: 0.0145, Validation Loss: 0.0016\n",
            "Epoch [110/200], Train Loss: 0.0122, Validation Loss: 0.0015\n",
            "Epoch [120/200], Train Loss: 0.0138, Validation Loss: 0.0027\n",
            "Epoch [130/200], Train Loss: 0.0147, Validation Loss: 0.0032\n",
            "Epoch [140/200], Train Loss: 0.0132, Validation Loss: 0.0027\n",
            "Epoch [150/200], Train Loss: 0.0076, Validation Loss: 0.0005\n",
            "Epoch [160/200], Train Loss: 0.0074, Validation Loss: 0.0010\n",
            "Epoch [170/200], Train Loss: 0.0089, Validation Loss: 0.0091\n",
            "Epoch [180/200], Train Loss: 0.0086, Validation Loss: 0.0461\n",
            "Epoch [190/200], Train Loss: 0.0111, Validation Loss: 0.0039\n",
            "Epoch [200/200], Train Loss: 0.0084, Validation Loss: 0.0005\n",
            "\n",
            "Training finished. Best model from Epoch 152 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2835, Validation Loss: 0.1278\n",
            "Epoch [20/200], Train Loss: 0.1069, Validation Loss: 0.2435\n",
            "Epoch [30/200], Train Loss: 0.0837, Validation Loss: 0.0086\n",
            "Epoch [40/200], Train Loss: 0.0757, Validation Loss: 0.1607\n",
            "Epoch [50/200], Train Loss: 0.0674, Validation Loss: 0.0023\n",
            "Epoch [60/200], Train Loss: 0.0400, Validation Loss: 0.0016\n",
            "Epoch [70/200], Train Loss: 0.0332, Validation Loss: 0.0004\n",
            "Epoch [80/200], Train Loss: 0.0354, Validation Loss: 0.0236\n",
            "Epoch [90/200], Train Loss: 0.0320, Validation Loss: 0.0099\n",
            "Epoch [100/200], Train Loss: 0.0313, Validation Loss: 0.0031\n",
            "Epoch [110/200], Train Loss: 0.0236, Validation Loss: 0.0098\n",
            "Epoch [120/200], Train Loss: 0.0250, Validation Loss: 0.0042\n",
            "Epoch [130/200], Train Loss: 0.0175, Validation Loss: 0.0066\n",
            "Epoch [140/200], Train Loss: 0.0207, Validation Loss: 0.0009\n",
            "Epoch [150/200], Train Loss: 0.0173, Validation Loss: 0.0333\n",
            "Epoch [160/200], Train Loss: 0.0149, Validation Loss: 0.0006\n",
            "Epoch [170/200], Train Loss: 0.0166, Validation Loss: 0.0079\n",
            "Epoch [180/200], Train Loss: 0.0146, Validation Loss: 0.0005\n",
            "Epoch [190/200], Train Loss: 0.0150, Validation Loss: 0.0442\n",
            "Epoch [200/200], Train Loss: 0.0126, Validation Loss: 0.0156\n",
            "\n",
            "Training finished. Best model from Epoch 155 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1960, Validation Loss: 0.1377\n",
            "Epoch [20/200], Train Loss: 0.1436, Validation Loss: 0.0044\n",
            "Epoch [30/200], Train Loss: 0.1115, Validation Loss: 0.0243\n",
            "Epoch [40/200], Train Loss: 0.0598, Validation Loss: 0.0137\n",
            "Epoch [50/200], Train Loss: 0.0574, Validation Loss: 0.0036\n",
            "Epoch [60/200], Train Loss: 0.0511, Validation Loss: 0.0035\n",
            "Epoch [70/200], Train Loss: 0.0384, Validation Loss: 0.0097\n",
            "Epoch [80/200], Train Loss: 0.0325, Validation Loss: 0.0390\n",
            "Epoch [90/200], Train Loss: 0.0279, Validation Loss: 0.0148\n",
            "Epoch [100/200], Train Loss: 0.0247, Validation Loss: 0.0068\n",
            "Epoch [110/200], Train Loss: 0.0245, Validation Loss: 0.1513\n",
            "Epoch [120/200], Train Loss: 0.0184, Validation Loss: 0.0156\n",
            "Epoch [130/200], Train Loss: 0.0170, Validation Loss: 0.0023\n",
            "Epoch [140/200], Train Loss: 0.0164, Validation Loss: 0.0357\n",
            "Epoch [150/200], Train Loss: 0.0172, Validation Loss: 0.0014\n",
            "Epoch [160/200], Train Loss: 0.0113, Validation Loss: 0.0025\n",
            "Epoch [170/200], Train Loss: 0.0108, Validation Loss: 0.0010\n",
            "Epoch [180/200], Train Loss: 0.0136, Validation Loss: 0.0053\n",
            "Epoch [190/200], Train Loss: 0.0117, Validation Loss: 0.0025\n",
            "Epoch [200/200], Train Loss: 0.0092, Validation Loss: 0.0024\n",
            "\n",
            "Training finished. Best model from Epoch 192 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1344, Validation Loss: 0.0338\n",
            "Epoch [20/200], Train Loss: 0.0990, Validation Loss: 0.0102\n",
            "Epoch [30/200], Train Loss: 0.0586, Validation Loss: 0.0082\n",
            "Epoch [40/200], Train Loss: 0.0428, Validation Loss: 0.0084\n",
            "Epoch [50/200], Train Loss: 0.0442, Validation Loss: 0.0101\n",
            "Epoch [60/200], Train Loss: 0.0333, Validation Loss: 0.0239\n",
            "Epoch [70/200], Train Loss: 0.0279, Validation Loss: 0.0694\n",
            "Epoch [80/200], Train Loss: 0.0208, Validation Loss: 0.0011\n",
            "Epoch [90/200], Train Loss: 0.0190, Validation Loss: 0.0041\n",
            "Epoch [100/200], Train Loss: 0.0225, Validation Loss: 0.0201\n",
            "Epoch [110/200], Train Loss: 0.0231, Validation Loss: 0.0014\n",
            "Epoch [120/200], Train Loss: 0.0180, Validation Loss: 0.0220\n",
            "Epoch [130/200], Train Loss: 0.0133, Validation Loss: 0.0006\n",
            "Epoch [140/200], Train Loss: 0.0167, Validation Loss: 0.0012\n",
            "Epoch [150/200], Train Loss: 0.0166, Validation Loss: 0.0013\n",
            "Epoch [160/200], Train Loss: 0.0145, Validation Loss: 0.0265\n",
            "Epoch [170/200], Train Loss: 0.0137, Validation Loss: 0.0003\n",
            "Epoch [180/200], Train Loss: 0.0108, Validation Loss: 0.0026\n",
            "Epoch [190/200], Train Loss: 0.0098, Validation Loss: 0.0068\n",
            "\n",
            "Early stopping triggered at epoch 191 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 141 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1721, Validation Loss: 0.0300\n",
            "Epoch [20/200], Train Loss: 0.0981, Validation Loss: 0.0158\n",
            "Epoch [30/200], Train Loss: 0.0678, Validation Loss: 0.0051\n",
            "Epoch [40/200], Train Loss: 0.0406, Validation Loss: 0.0394\n",
            "Epoch [50/200], Train Loss: 0.0378, Validation Loss: 0.1383\n",
            "Epoch [60/200], Train Loss: 0.0351, Validation Loss: 0.0512\n",
            "Epoch [70/200], Train Loss: 0.0308, Validation Loss: 0.0013\n",
            "Epoch [80/200], Train Loss: 0.0236, Validation Loss: 0.0008\n",
            "Epoch [90/200], Train Loss: 0.0213, Validation Loss: 0.3348\n",
            "Epoch [100/200], Train Loss: 0.0238, Validation Loss: 0.0015\n",
            "Epoch [110/200], Train Loss: 0.0185, Validation Loss: 0.0003\n",
            "Epoch [120/200], Train Loss: 0.0110, Validation Loss: 0.0097\n",
            "Epoch [130/200], Train Loss: 0.0128, Validation Loss: 0.0002\n",
            "Epoch [140/200], Train Loss: 0.0114, Validation Loss: 0.0389\n",
            "Epoch [150/200], Train Loss: 0.0079, Validation Loss: 0.0308\n",
            "Epoch [160/200], Train Loss: 0.0096, Validation Loss: 0.0013\n",
            "Epoch [170/200], Train Loss: 0.0088, Validation Loss: 0.0004\n",
            "Epoch [180/200], Train Loss: 0.0089, Validation Loss: 0.0020\n",
            "\n",
            "Early stopping triggered at epoch 180 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 130 with Validation Loss 0.0002 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2125, Validation Loss: 0.8525\n",
            "Epoch [20/200], Train Loss: 0.0888, Validation Loss: 0.1493\n",
            "Epoch [30/200], Train Loss: 0.0714, Validation Loss: 0.0473\n",
            "Epoch [40/200], Train Loss: 0.0675, Validation Loss: 0.0059\n",
            "Epoch [50/200], Train Loss: 0.0446, Validation Loss: 0.1262\n",
            "Epoch [60/200], Train Loss: 0.0338, Validation Loss: 0.0008\n",
            "Epoch [70/200], Train Loss: 0.0350, Validation Loss: 0.0583\n",
            "Epoch [80/200], Train Loss: 0.0301, Validation Loss: 0.0017\n",
            "Epoch [90/200], Train Loss: 0.0312, Validation Loss: 0.0013\n",
            "Epoch [100/200], Train Loss: 0.0257, Validation Loss: 0.1531\n",
            "Epoch [110/200], Train Loss: 0.0289, Validation Loss: 0.0525\n",
            "Epoch [120/200], Train Loss: 0.0235, Validation Loss: 0.0121\n",
            "Epoch [130/200], Train Loss: 0.0163, Validation Loss: 0.0025\n",
            "Epoch [140/200], Train Loss: 0.0202, Validation Loss: 0.1811\n",
            "Epoch [150/200], Train Loss: 0.0171, Validation Loss: 0.0307\n",
            "Epoch [160/200], Train Loss: 0.0160, Validation Loss: 0.0113\n",
            "\n",
            "Early stopping triggered at epoch 165 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 115 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2129, Validation Loss: 0.0733\n",
            "Epoch [20/200], Train Loss: 0.1335, Validation Loss: 0.0146\n",
            "Epoch [30/200], Train Loss: 0.0827, Validation Loss: 0.0959\n",
            "Epoch [40/200], Train Loss: 0.0635, Validation Loss: 0.0069\n",
            "Epoch [50/200], Train Loss: 0.0423, Validation Loss: 0.0029\n",
            "Epoch [60/200], Train Loss: 0.0282, Validation Loss: 0.0753\n",
            "Epoch [70/200], Train Loss: 0.0277, Validation Loss: 0.0368\n",
            "Epoch [80/200], Train Loss: 0.0322, Validation Loss: 0.0014\n",
            "Epoch [90/200], Train Loss: 0.0271, Validation Loss: 0.0059\n",
            "Epoch [100/200], Train Loss: 0.0212, Validation Loss: 0.0181\n",
            "Epoch [110/200], Train Loss: 0.0183, Validation Loss: 0.0016\n",
            "Epoch [120/200], Train Loss: 0.0192, Validation Loss: 0.0231\n",
            "Epoch [130/200], Train Loss: 0.0130, Validation Loss: 0.0160\n",
            "Epoch [140/200], Train Loss: 0.0114, Validation Loss: 0.0063\n",
            "Epoch [150/200], Train Loss: 0.0095, Validation Loss: 0.0002\n",
            "Epoch [160/200], Train Loss: 0.0098, Validation Loss: 0.0020\n",
            "Epoch [170/200], Train Loss: 0.0090, Validation Loss: 0.0003\n",
            "Epoch [180/200], Train Loss: 0.0076, Validation Loss: 0.0006\n",
            "\n",
            "Early stopping triggered at epoch 184 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 134 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1241, Validation Loss: 0.0539\n",
            "Epoch [20/200], Train Loss: 0.0799, Validation Loss: 0.1288\n",
            "Epoch [30/200], Train Loss: 0.0618, Validation Loss: 0.1807\n",
            "Epoch [40/200], Train Loss: 0.0515, Validation Loss: 0.0244\n",
            "Epoch [50/200], Train Loss: 0.0360, Validation Loss: 0.0316\n",
            "Epoch [60/200], Train Loss: 0.0318, Validation Loss: 0.0643\n",
            "Epoch [70/200], Train Loss: 0.0291, Validation Loss: 0.0027\n",
            "Epoch [80/200], Train Loss: 0.0196, Validation Loss: 0.0866\n",
            "Epoch [90/200], Train Loss: 0.0175, Validation Loss: 0.0587\n",
            "Epoch [100/200], Train Loss: 0.0234, Validation Loss: 0.0006\n",
            "Epoch [110/200], Train Loss: 0.0206, Validation Loss: 0.0061\n",
            "Epoch [120/200], Train Loss: 0.0194, Validation Loss: 0.0181\n",
            "\n",
            "Early stopping triggered at epoch 124 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 74 with Validation Loss 0.0004 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1868, Validation Loss: 0.0603\n",
            "Epoch [20/200], Train Loss: 0.0867, Validation Loss: 0.2966\n",
            "Epoch [30/200], Train Loss: 0.0498, Validation Loss: 0.0143\n",
            "Epoch [40/200], Train Loss: 0.0552, Validation Loss: 0.0032\n",
            "Epoch [50/200], Train Loss: 0.0386, Validation Loss: 0.0038\n",
            "Epoch [60/200], Train Loss: 0.0374, Validation Loss: 0.0014\n",
            "Epoch [70/200], Train Loss: 0.0316, Validation Loss: 0.0618\n",
            "Epoch [80/200], Train Loss: 0.0186, Validation Loss: 0.0127\n",
            "Epoch [90/200], Train Loss: 0.0227, Validation Loss: 0.0006\n",
            "Epoch [100/200], Train Loss: 0.0210, Validation Loss: 0.0002\n",
            "Epoch [110/200], Train Loss: 0.0167, Validation Loss: 0.0589\n",
            "Epoch [120/200], Train Loss: 0.0179, Validation Loss: 0.0003\n",
            "Epoch [130/200], Train Loss: 0.0136, Validation Loss: 0.0035\n",
            "Epoch [140/200], Train Loss: 0.0110, Validation Loss: 0.0169\n",
            "Epoch [150/200], Train Loss: 0.0100, Validation Loss: 0.0029\n",
            "Epoch [160/200], Train Loss: 0.0108, Validation Loss: 0.0062\n",
            "Epoch [170/200], Train Loss: 0.0088, Validation Loss: 0.0067\n",
            "Epoch [180/200], Train Loss: 0.0074, Validation Loss: 0.0127\n",
            "Epoch [190/200], Train Loss: 0.0074, Validation Loss: 0.0001\n",
            "Epoch [200/200], Train Loss: 0.0078, Validation Loss: 0.0003\n",
            "\n",
            "Training finished. Best model from Epoch 167 with Validation Loss 0.0000 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2117, Validation Loss: 0.1040\n",
            "Epoch [20/200], Train Loss: 0.1525, Validation Loss: 0.1115\n",
            "Epoch [30/200], Train Loss: 0.0882, Validation Loss: 0.0051\n",
            "Epoch [40/200], Train Loss: 0.0698, Validation Loss: 0.0158\n",
            "Epoch [50/200], Train Loss: 0.0356, Validation Loss: 0.0054\n",
            "Epoch [60/200], Train Loss: 0.0428, Validation Loss: 0.0517\n",
            "Epoch [70/200], Train Loss: 0.0373, Validation Loss: 0.0284\n",
            "Epoch [80/200], Train Loss: 0.0268, Validation Loss: 0.0009\n",
            "Epoch [90/200], Train Loss: 0.0343, Validation Loss: 0.0039\n",
            "Epoch [100/200], Train Loss: 0.0278, Validation Loss: 0.0945\n",
            "Epoch [110/200], Train Loss: 0.0229, Validation Loss: 0.0483\n",
            "Epoch [120/200], Train Loss: 0.0220, Validation Loss: 0.0028\n",
            "Epoch [130/200], Train Loss: 0.0208, Validation Loss: 0.0009\n",
            "Epoch [140/200], Train Loss: 0.0218, Validation Loss: 0.0267\n",
            "Epoch [150/200], Train Loss: 0.0169, Validation Loss: 0.0003\n",
            "Epoch [160/200], Train Loss: 0.0160, Validation Loss: 0.0384\n",
            "Epoch [170/200], Train Loss: 0.0194, Validation Loss: 0.0152\n",
            "Epoch [180/200], Train Loss: 0.0122, Validation Loss: 0.0295\n",
            "Epoch [190/200], Train Loss: 0.0150, Validation Loss: 0.0014\n",
            "\n",
            "Early stopping triggered at epoch 193 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 143 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2436, Validation Loss: 0.4240\n",
            "Epoch [20/200], Train Loss: 0.1190, Validation Loss: 0.0890\n",
            "Epoch [30/200], Train Loss: 0.1121, Validation Loss: 0.2788\n",
            "Epoch [40/200], Train Loss: 0.0630, Validation Loss: 0.0576\n",
            "Epoch [50/200], Train Loss: 0.0467, Validation Loss: 0.0518\n",
            "Epoch [60/200], Train Loss: 0.0395, Validation Loss: 0.0042\n",
            "Epoch [70/200], Train Loss: 0.0410, Validation Loss: 0.0207\n",
            "Epoch [80/200], Train Loss: 0.0382, Validation Loss: 0.0023\n",
            "Epoch [90/200], Train Loss: 0.0321, Validation Loss: 0.0025\n",
            "Epoch [100/200], Train Loss: 0.0242, Validation Loss: 0.0013\n",
            "Epoch [110/200], Train Loss: 0.0263, Validation Loss: 0.0193\n",
            "Epoch [120/200], Train Loss: 0.0237, Validation Loss: 0.0034\n",
            "Epoch [130/200], Train Loss: 0.0170, Validation Loss: 0.0010\n",
            "Epoch [140/200], Train Loss: 0.0241, Validation Loss: 0.0036\n",
            "Epoch [150/200], Train Loss: 0.0194, Validation Loss: 0.0029\n",
            "Epoch [160/200], Train Loss: 0.0193, Validation Loss: 0.0002\n",
            "Epoch [170/200], Train Loss: 0.0168, Validation Loss: 0.0147\n",
            "Epoch [180/200], Train Loss: 0.0142, Validation Loss: 0.0001\n",
            "Epoch [190/200], Train Loss: 0.0149, Validation Loss: 0.0009\n",
            "Epoch [200/200], Train Loss: 0.0117, Validation Loss: 0.0091\n",
            "\n",
            "Training finished. Best model from Epoch 180 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1006, Validation Loss: 0.1077\n",
            "Epoch [20/200], Train Loss: 0.0698, Validation Loss: 0.0830\n",
            "Epoch [30/200], Train Loss: 0.0673, Validation Loss: 0.0271\n",
            "Epoch [40/200], Train Loss: 0.0369, Validation Loss: 0.0451\n",
            "Epoch [50/200], Train Loss: 0.0336, Validation Loss: 0.0186\n",
            "Epoch [60/200], Train Loss: 0.0293, Validation Loss: 0.0215\n",
            "Epoch [70/200], Train Loss: 0.0259, Validation Loss: 0.0017\n",
            "Epoch [80/200], Train Loss: 0.0285, Validation Loss: 0.0002\n",
            "Epoch [90/200], Train Loss: 0.0176, Validation Loss: 0.0586\n",
            "Epoch [100/200], Train Loss: 0.0187, Validation Loss: 0.0009\n",
            "Epoch [110/200], Train Loss: 0.0230, Validation Loss: 0.0035\n",
            "Epoch [120/200], Train Loss: 0.0170, Validation Loss: 0.0057\n",
            "Epoch [130/200], Train Loss: 0.0159, Validation Loss: 0.0196\n",
            "Epoch [140/200], Train Loss: 0.0077, Validation Loss: 0.0019\n",
            "Epoch [150/200], Train Loss: 0.0141, Validation Loss: 0.0497\n",
            "Epoch [160/200], Train Loss: 0.0121, Validation Loss: 0.0042\n",
            "Epoch [170/200], Train Loss: 0.0120, Validation Loss: 0.0004\n",
            "\n",
            "Early stopping triggered at epoch 175 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 125 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1528, Validation Loss: 0.1788\n",
            "Epoch [20/200], Train Loss: 0.0872, Validation Loss: 0.1263\n",
            "Epoch [30/200], Train Loss: 0.0784, Validation Loss: 0.0040\n",
            "Epoch [40/200], Train Loss: 0.0461, Validation Loss: 0.0085\n",
            "Epoch [50/200], Train Loss: 0.0286, Validation Loss: 0.0100\n",
            "Epoch [60/200], Train Loss: 0.0302, Validation Loss: 0.0674\n",
            "Epoch [70/200], Train Loss: 0.0265, Validation Loss: 0.0557\n",
            "Epoch [80/200], Train Loss: 0.0223, Validation Loss: 0.0019\n",
            "Epoch [90/200], Train Loss: 0.0169, Validation Loss: 0.0089\n",
            "Epoch [100/200], Train Loss: 0.0135, Validation Loss: 0.0082\n",
            "Epoch [110/200], Train Loss: 0.0175, Validation Loss: 0.0217\n",
            "Epoch [120/200], Train Loss: 0.0105, Validation Loss: 0.0006\n",
            "Epoch [130/200], Train Loss: 0.0099, Validation Loss: 0.0038\n",
            "Epoch [140/200], Train Loss: 0.0125, Validation Loss: 0.0479\n",
            "Epoch [150/200], Train Loss: 0.0105, Validation Loss: 0.0011\n",
            "Epoch [160/200], Train Loss: 0.0101, Validation Loss: 0.0103\n",
            "Epoch [170/200], Train Loss: 0.0072, Validation Loss: 0.0233\n",
            "Epoch [180/200], Train Loss: 0.0065, Validation Loss: 0.0005\n",
            "\n",
            "Early stopping triggered at epoch 185 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 135 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2199, Validation Loss: 0.0712\n",
            "Epoch [20/200], Train Loss: 0.1022, Validation Loss: 0.1972\n",
            "Epoch [30/200], Train Loss: 0.1079, Validation Loss: 0.0535\n",
            "Epoch [40/200], Train Loss: 0.0476, Validation Loss: 0.2108\n",
            "Epoch [50/200], Train Loss: 0.0491, Validation Loss: 0.0045\n",
            "Epoch [60/200], Train Loss: 0.0660, Validation Loss: 0.0046\n",
            "Epoch [70/200], Train Loss: 0.0439, Validation Loss: 0.0073\n",
            "Epoch [80/200], Train Loss: 0.0267, Validation Loss: 0.0197\n",
            "Epoch [90/200], Train Loss: 0.0304, Validation Loss: 0.0045\n",
            "Epoch [100/200], Train Loss: 0.0275, Validation Loss: 0.0033\n",
            "Epoch [110/200], Train Loss: 0.0201, Validation Loss: 0.0169\n",
            "Epoch [120/200], Train Loss: 0.0139, Validation Loss: 0.0013\n",
            "Epoch [130/200], Train Loss: 0.0188, Validation Loss: 0.0013\n",
            "Epoch [140/200], Train Loss: 0.0187, Validation Loss: 0.0024\n",
            "Epoch [150/200], Train Loss: 0.0148, Validation Loss: 0.0092\n",
            "Epoch [160/200], Train Loss: 0.0175, Validation Loss: 0.0002\n",
            "Epoch [170/200], Train Loss: 0.0177, Validation Loss: 0.0003\n",
            "Epoch [180/200], Train Loss: 0.0103, Validation Loss: 0.0030\n",
            "Epoch [190/200], Train Loss: 0.0104, Validation Loss: 0.1624\n",
            "Epoch [200/200], Train Loss: 0.0087, Validation Loss: 0.0002\n",
            "\n",
            "Training finished. Best model from Epoch 191 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2265, Validation Loss: 0.7900\n",
            "Epoch [20/200], Train Loss: 0.1173, Validation Loss: 0.0271\n",
            "Epoch [30/200], Train Loss: 0.0801, Validation Loss: 0.0309\n",
            "Epoch [40/200], Train Loss: 0.0504, Validation Loss: 0.0599\n",
            "Epoch [50/200], Train Loss: 0.0576, Validation Loss: 0.0437\n",
            "Epoch [60/200], Train Loss: 0.0411, Validation Loss: 0.0315\n",
            "Epoch [70/200], Train Loss: 0.0344, Validation Loss: 0.0041\n",
            "Epoch [80/200], Train Loss: 0.0268, Validation Loss: 0.0056\n",
            "Epoch [90/200], Train Loss: 0.0304, Validation Loss: 0.0292\n",
            "Epoch [100/200], Train Loss: 0.0303, Validation Loss: 0.1206\n",
            "Epoch [110/200], Train Loss: 0.0267, Validation Loss: 0.0033\n",
            "Epoch [120/200], Train Loss: 0.0243, Validation Loss: 0.0029\n",
            "Epoch [130/200], Train Loss: 0.0223, Validation Loss: 0.0008\n",
            "Epoch [140/200], Train Loss: 0.0204, Validation Loss: 0.0203\n",
            "Epoch [150/200], Train Loss: 0.0188, Validation Loss: 0.0070\n",
            "Epoch [160/200], Train Loss: 0.0220, Validation Loss: 0.0370\n",
            "Epoch [170/200], Train Loss: 0.0176, Validation Loss: 0.0025\n",
            "Epoch [180/200], Train Loss: 0.0106, Validation Loss: 0.0027\n",
            "Epoch [190/200], Train Loss: 0.0170, Validation Loss: 0.0027\n",
            "Epoch [200/200], Train Loss: 0.0158, Validation Loss: 0.0019\n",
            "\n",
            "Training finished. Best model from Epoch 167 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1222, Validation Loss: 0.0558\n",
            "Epoch [20/200], Train Loss: 0.0820, Validation Loss: 0.0125\n",
            "Epoch [30/200], Train Loss: 0.0541, Validation Loss: 0.0099\n",
            "Epoch [40/200], Train Loss: 0.0472, Validation Loss: 0.5998\n",
            "Epoch [50/200], Train Loss: 0.0393, Validation Loss: 0.0018\n",
            "Epoch [60/200], Train Loss: 0.0351, Validation Loss: 0.0082\n",
            "Epoch [70/200], Train Loss: 0.0393, Validation Loss: 0.0031\n",
            "Epoch [80/200], Train Loss: 0.0221, Validation Loss: 0.0027\n",
            "Epoch [90/200], Train Loss: 0.0260, Validation Loss: 0.0004\n",
            "Epoch [100/200], Train Loss: 0.0166, Validation Loss: 0.0952\n",
            "Epoch [110/200], Train Loss: 0.0159, Validation Loss: 0.0317\n",
            "Epoch [120/200], Train Loss: 0.0178, Validation Loss: 0.0002\n",
            "Epoch [130/200], Train Loss: 0.0139, Validation Loss: 0.2033\n",
            "Epoch [140/200], Train Loss: 0.0154, Validation Loss: 0.0027\n",
            "Epoch [150/200], Train Loss: 0.0155, Validation Loss: 0.0010\n",
            "Epoch [160/200], Train Loss: 0.0095, Validation Loss: 0.0067\n",
            "Epoch [170/200], Train Loss: 0.0120, Validation Loss: 0.0004\n",
            "Epoch [180/200], Train Loss: 0.0118, Validation Loss: 0.0043\n",
            "Epoch [190/200], Train Loss: 0.0120, Validation Loss: 0.0027\n",
            "Epoch [200/200], Train Loss: 0.0096, Validation Loss: 0.0007\n",
            "\n",
            "Training finished. Best model from Epoch 176 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1770, Validation Loss: 0.5656\n",
            "Epoch [20/200], Train Loss: 0.0934, Validation Loss: 0.1552\n",
            "Epoch [30/200], Train Loss: 0.0530, Validation Loss: 0.1079\n",
            "Epoch [40/200], Train Loss: 0.0541, Validation Loss: 0.0421\n",
            "Epoch [50/200], Train Loss: 0.0256, Validation Loss: 0.0060\n",
            "Epoch [60/200], Train Loss: 0.0314, Validation Loss: 0.0402\n",
            "Epoch [70/200], Train Loss: 0.0332, Validation Loss: 0.0023\n",
            "Epoch [80/200], Train Loss: 0.0211, Validation Loss: 0.0149\n",
            "Epoch [90/200], Train Loss: 0.0186, Validation Loss: 0.0123\n",
            "Epoch [100/200], Train Loss: 0.0201, Validation Loss: 0.0053\n",
            "Epoch [110/200], Train Loss: 0.0135, Validation Loss: 0.0100\n",
            "\n",
            "Early stopping triggered at epoch 111 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 61 with Validation Loss 0.0005 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2009, Validation Loss: 0.0195\n",
            "Epoch [20/200], Train Loss: 0.0999, Validation Loss: 0.0124\n",
            "Epoch [30/200], Train Loss: 0.0813, Validation Loss: 0.0130\n",
            "Epoch [40/200], Train Loss: 0.0716, Validation Loss: 0.1122\n",
            "Epoch [50/200], Train Loss: 0.0367, Validation Loss: 0.0021\n",
            "Epoch [60/200], Train Loss: 0.0510, Validation Loss: 0.0293\n",
            "Epoch [70/200], Train Loss: 0.0335, Validation Loss: 0.0253\n",
            "Epoch [80/200], Train Loss: 0.0414, Validation Loss: 0.0015\n",
            "Epoch [90/200], Train Loss: 0.0285, Validation Loss: 0.0124\n",
            "Epoch [100/200], Train Loss: 0.0285, Validation Loss: 0.0008\n",
            "Epoch [110/200], Train Loss: 0.0299, Validation Loss: 0.3415\n",
            "Epoch [120/200], Train Loss: 0.0276, Validation Loss: 0.0087\n",
            "\n",
            "Early stopping triggered at epoch 127 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 77 with Validation Loss 0.0004 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2179, Validation Loss: 0.2041\n",
            "Epoch [20/200], Train Loss: 0.1200, Validation Loss: 0.1704\n",
            "Epoch [30/200], Train Loss: 0.1054, Validation Loss: 0.0266\n",
            "Epoch [40/200], Train Loss: 0.0617, Validation Loss: 0.0834\n",
            "Epoch [50/200], Train Loss: 0.0481, Validation Loss: 0.0159\n",
            "Epoch [60/200], Train Loss: 0.0491, Validation Loss: 0.0028\n",
            "Epoch [70/200], Train Loss: 0.0309, Validation Loss: 0.0024\n",
            "Epoch [80/200], Train Loss: 0.0390, Validation Loss: 0.0034\n",
            "Epoch [90/200], Train Loss: 0.0289, Validation Loss: 0.0061\n",
            "Epoch [100/200], Train Loss: 0.0155, Validation Loss: 0.0023\n",
            "Epoch [110/200], Train Loss: 0.0228, Validation Loss: 0.0173\n",
            "Epoch [120/200], Train Loss: 0.0258, Validation Loss: 0.0044\n",
            "Epoch [130/200], Train Loss: 0.0218, Validation Loss: 0.0059\n",
            "Epoch [140/200], Train Loss: 0.0154, Validation Loss: 0.0026\n",
            "Epoch [150/200], Train Loss: 0.0151, Validation Loss: 0.0005\n",
            "Epoch [160/200], Train Loss: 0.0179, Validation Loss: 0.0004\n",
            "Epoch [170/200], Train Loss: 0.0160, Validation Loss: 0.1019\n",
            "Epoch [180/200], Train Loss: 0.0103, Validation Loss: 0.0014\n",
            "Epoch [190/200], Train Loss: 0.0130, Validation Loss: 0.0059\n",
            "Epoch [200/200], Train Loss: 0.0121, Validation Loss: 0.0065\n",
            "\n",
            "Training finished. Best model from Epoch 192 with Validation Loss 0.0000 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1041, Validation Loss: 0.5545\n",
            "Epoch [20/200], Train Loss: 0.0810, Validation Loss: 0.0416\n",
            "Epoch [30/200], Train Loss: 0.0573, Validation Loss: 0.0079\n",
            "Epoch [40/200], Train Loss: 0.0534, Validation Loss: 0.1118\n",
            "Epoch [50/200], Train Loss: 0.0477, Validation Loss: 0.0027\n",
            "Epoch [60/200], Train Loss: 0.0720, Validation Loss: 0.0726\n",
            "Epoch [70/200], Train Loss: 0.0277, Validation Loss: 0.0267\n",
            "Epoch [80/200], Train Loss: 0.0223, Validation Loss: 0.0304\n",
            "Epoch [90/200], Train Loss: 0.0241, Validation Loss: 0.0020\n",
            "Epoch [100/200], Train Loss: 0.0223, Validation Loss: 0.0485\n",
            "Epoch [110/200], Train Loss: 0.0204, Validation Loss: 0.0464\n",
            "Epoch [120/200], Train Loss: 0.0214, Validation Loss: 0.0040\n",
            "Epoch [130/200], Train Loss: 0.0144, Validation Loss: 0.0052\n",
            "Epoch [140/200], Train Loss: 0.0119, Validation Loss: 0.0020\n",
            "Epoch [150/200], Train Loss: 0.0124, Validation Loss: 0.0024\n",
            "Epoch [160/200], Train Loss: 0.0134, Validation Loss: 0.0034\n",
            "Epoch [170/200], Train Loss: 0.0180, Validation Loss: 0.0016\n",
            "Epoch [180/200], Train Loss: 0.0102, Validation Loss: 0.0005\n",
            "Epoch [190/200], Train Loss: 0.0100, Validation Loss: 0.0027\n",
            "Epoch [200/200], Train Loss: 0.0132, Validation Loss: 0.0040\n",
            "\n",
            "Training finished. Best model from Epoch 164 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1392, Validation Loss: 0.0305\n",
            "Epoch [20/200], Train Loss: 0.1053, Validation Loss: 0.3177\n",
            "Epoch [30/200], Train Loss: 0.0816, Validation Loss: 0.0724\n",
            "Epoch [40/200], Train Loss: 0.0556, Validation Loss: 0.8064\n",
            "Epoch [50/200], Train Loss: 0.0391, Validation Loss: 0.0165\n",
            "Epoch [60/200], Train Loss: 0.0373, Validation Loss: 0.0848\n",
            "Epoch [70/200], Train Loss: 0.0363, Validation Loss: 0.0014\n",
            "Epoch [80/200], Train Loss: 0.0256, Validation Loss: 0.0249\n",
            "Epoch [90/200], Train Loss: 0.0263, Validation Loss: 0.0029\n",
            "Epoch [100/200], Train Loss: 0.0198, Validation Loss: 0.0313\n",
            "Epoch [110/200], Train Loss: 0.0211, Validation Loss: 0.0222\n",
            "Epoch [120/200], Train Loss: 0.0136, Validation Loss: 0.0022\n",
            "Epoch [130/200], Train Loss: 0.0218, Validation Loss: 0.0003\n",
            "Epoch [140/200], Train Loss: 0.0144, Validation Loss: 0.0015\n",
            "Epoch [150/200], Train Loss: 0.0154, Validation Loss: 0.0027\n",
            "Epoch [160/200], Train Loss: 0.0102, Validation Loss: 0.0022\n",
            "Epoch [170/200], Train Loss: 0.0108, Validation Loss: 0.0011\n",
            "Epoch [180/200], Train Loss: 0.0113, Validation Loss: 0.0234\n",
            "Epoch [190/200], Train Loss: 0.0096, Validation Loss: 0.0036\n",
            "Epoch [200/200], Train Loss: 0.0068, Validation Loss: 0.0044\n",
            "\n",
            "Training finished. Best model from Epoch 166 with Validation Loss 0.0001 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2135, Validation Loss: 0.3040\n",
            "Epoch [20/200], Train Loss: 0.1277, Validation Loss: 0.0024\n",
            "Epoch [30/200], Train Loss: 0.0800, Validation Loss: 0.5400\n",
            "Epoch [40/200], Train Loss: 0.0766, Validation Loss: 0.0322\n",
            "Epoch [50/200], Train Loss: 0.0673, Validation Loss: 0.0149\n",
            "Epoch [60/200], Train Loss: 0.0513, Validation Loss: 0.0032\n",
            "Epoch [70/200], Train Loss: 0.0317, Validation Loss: 0.0066\n",
            "Epoch [80/200], Train Loss: 0.0346, Validation Loss: 0.0068\n",
            "Epoch [90/200], Train Loss: 0.0299, Validation Loss: 0.0036\n",
            "\n",
            "Early stopping triggered at epoch 92 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 42 with Validation Loss 0.0013 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.2834, Validation Loss: 0.0906\n",
            "Epoch [20/200], Train Loss: 0.1365, Validation Loss: 0.2856\n",
            "Epoch [30/200], Train Loss: 0.1013, Validation Loss: 0.1665\n",
            "Epoch [40/200], Train Loss: 0.0730, Validation Loss: 0.0135\n",
            "Epoch [50/200], Train Loss: 0.0637, Validation Loss: 0.0321\n",
            "Epoch [60/200], Train Loss: 0.0530, Validation Loss: 0.0145\n",
            "Epoch [70/200], Train Loss: 0.0356, Validation Loss: 0.2896\n",
            "Epoch [80/200], Train Loss: 0.0372, Validation Loss: 0.0004\n",
            "Epoch [90/200], Train Loss: 0.0291, Validation Loss: 0.0735\n",
            "Epoch [100/200], Train Loss: 0.0220, Validation Loss: 0.0541\n",
            "Epoch [110/200], Train Loss: 0.0306, Validation Loss: 0.0446\n",
            "Epoch [120/200], Train Loss: 0.0237, Validation Loss: 0.0051\n",
            "Epoch [130/200], Train Loss: 0.0224, Validation Loss: 0.0056\n",
            "\n",
            "Early stopping triggered at epoch 130 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 80 with Validation Loss 0.0004 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1083, Validation Loss: 0.1991\n",
            "Epoch [20/200], Train Loss: 0.0775, Validation Loss: 0.0442\n",
            "Epoch [30/200], Train Loss: 0.0417, Validation Loss: 0.0238\n",
            "Epoch [40/200], Train Loss: 0.0363, Validation Loss: 0.1106\n",
            "Epoch [50/200], Train Loss: 0.0312, Validation Loss: 0.0374\n",
            "Epoch [60/200], Train Loss: 0.0278, Validation Loss: 0.0629\n",
            "Epoch [70/200], Train Loss: 0.0301, Validation Loss: 0.0018\n",
            "Epoch [80/200], Train Loss: 0.0280, Validation Loss: 0.0002\n",
            "Epoch [90/200], Train Loss: 0.0181, Validation Loss: 0.0054\n",
            "Epoch [100/200], Train Loss: 0.0123, Validation Loss: 0.0024\n",
            "Epoch [110/200], Train Loss: 0.0132, Validation Loss: 0.0808\n",
            "Epoch [120/200], Train Loss: 0.0137, Validation Loss: 0.0040\n",
            "Epoch [130/200], Train Loss: 0.0144, Validation Loss: 0.0104\n",
            "Epoch [140/200], Train Loss: 0.0144, Validation Loss: 0.0001\n",
            "Epoch [150/200], Train Loss: 0.0131, Validation Loss: 0.0023\n",
            "Epoch [160/200], Train Loss: 0.0081, Validation Loss: 0.0050\n",
            "Epoch [170/200], Train Loss: 0.0114, Validation Loss: 0.0487\n",
            "Epoch [180/200], Train Loss: 0.0088, Validation Loss: 0.0035\n",
            "Epoch [190/200], Train Loss: 0.0080, Validation Loss: 0.0032\n",
            "Epoch [200/200], Train Loss: 0.0120, Validation Loss: 0.0021\n",
            "\n",
            "Training finished. Best model from Epoch 182 with Validation Loss 0.0000 is being saved.\n",
            "Epoch [10/200], Train Loss: 0.1649, Validation Loss: 0.1276\n",
            "Epoch [20/200], Train Loss: 0.0891, Validation Loss: 0.0051\n",
            "Epoch [30/200], Train Loss: 0.0642, Validation Loss: 0.4492\n",
            "Epoch [40/200], Train Loss: 0.0359, Validation Loss: 0.0029\n",
            "Epoch [50/200], Train Loss: 0.0508, Validation Loss: 0.0209\n",
            "Epoch [60/200], Train Loss: 0.0217, Validation Loss: 0.0351\n",
            "Epoch [70/200], Train Loss: 0.0260, Validation Loss: 0.0027\n",
            "Epoch [80/200], Train Loss: 0.0236, Validation Loss: 0.0169\n",
            "Epoch [90/200], Train Loss: 0.0154, Validation Loss: 0.0172\n",
            "Epoch [100/200], Train Loss: 0.0141, Validation Loss: 0.0077\n",
            "Epoch [110/200], Train Loss: 0.0136, Validation Loss: 0.0003\n",
            "Epoch [120/200], Train Loss: 0.0166, Validation Loss: 0.0017\n",
            "Epoch [130/200], Train Loss: 0.0123, Validation Loss: 0.0026\n",
            "Epoch [140/200], Train Loss: 0.0081, Validation Loss: 0.0060\n",
            "Epoch [150/200], Train Loss: 0.0111, Validation Loss: 0.0019\n",
            "Epoch [160/200], Train Loss: 0.0115, Validation Loss: 0.0060\n",
            "Epoch [170/200], Train Loss: 0.0106, Validation Loss: 0.0007\n",
            "\n",
            "Early stopping triggered at epoch 179 as validation loss did not improve for 50 epochs.\n",
            "\n",
            "Training finished. Best model from Epoch 129 with Validation Loss 0.0001 is being saved.\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "logger = ConsoleLogger()\n",
        "for i in range(10):\n",
        "    model_save_path = os.path.join(model_path, f\"step{i+1}\")\n",
        "    os.makedirs(model_save_path, exist_ok=True)\n",
        "    for model_creator in model_creators:\n",
        "        best_model_path = os.path.join(model_save_path, model_creator.get_save_name() + f\"checkpoint.pth\")\n",
        "        scaler_save_path = os.path.join(model_save_path, model_creator.get_save_name() + f\"scaler.joblib\")\n",
        "        scaler_manager = ScalerManager(scaler_save_path)\n",
        "        model_manager = ModelManager(best_model_path)\n",
        "        context = Context(device, model_manager, scaler_manager)\n",
        "        context.train(learning_input, StandardScaler(), model_creator, optimizer_creator, loss_func_creator, logger\n",
        "                          , 0.2, 42, 0.001, 200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9e144b16",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from Users.project.src.base.logger import ConsoleLogger\n",
        "\n",
        "logger = FileLogger()\n",
        "# model_creators = [SimpleModel_128_Hidden_1_Creator(), SimpleModel_128_Hidden_2_Creator()\n",
        "#                   , SimpleModel_64_Hidden_1_Creator(), SimpleModel_64_Hidden_2_Creator()]\n",
        "\n",
        "for i in range(10):\n",
        "    model_save_path = os.path.join(model_path, f\"step{i+1}\")\n",
        "    log_save_path = os.path.join(log_path, f\"step{i+1}\")\n",
        "    os.makedirs(log_save_path, exist_ok=True)\n",
        "    for model_creator in model_creators:\n",
        "        best_model_path = os.path.join(model_save_path, model_creator.get_save_name() + f\"checkpoint.pth\")\n",
        "        scaler_save_path = os.path.join(model_save_path, model_creator.get_save_name() + f\"scaler.joblib\")\n",
        "        f_log_save_path = os.path.join(log_save_path, model_creator.get_save_name() + f\"log.txt\")\n",
        "        scaler_manager = ScalerManager(scaler_save_path)\n",
        "        model_manager = ModelManager(best_model_path)\n",
        "        context = Context(device, model_manager, scaler_manager)\n",
        "        logger.open(f_log_save_path, \"w\")\n",
        "        context.test_df(features, labels, model_creator, logger)\n",
        "        logger.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "455a241e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from Users.project.src.data_container.data_container import AzureStorageAccess\n",
        "\n",
        "\n",
        "# s = set()\n",
        "# data_access = AzureStorageAccess()\n",
        "# for file in data_access.get_all_file():\n",
        "#     if \"race_control_messages.csv\" not in file.name:\n",
        "#         continue\n",
        "#     file_name = file.name\n",
        "#     df = data_access.read_csv_from_blob(file_name)\n",
        "#     for i in df[\"Message\"]:\n",
        "#         if \"SAFETY\" in i:\n",
        "#             s.add(i)\n",
        "\n",
        "# for i in s:\n",
        "#     print(i)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
